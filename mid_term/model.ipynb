{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cu121'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim     # for constructing optimizer\n",
    "import torchvision.models as models\n",
    "from module import *\n",
    "from function import *\n",
    "\n",
    "# 1. preparing the dataset\n",
    "class GDdataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.data = pd.read_csv(path)\n",
    "        SFR = torch.tensor(self.data.iloc[:, 2:46].values)\n",
    "        blocks = [SFR[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] # 将36列中的每4列合并成一个2*2矩阵，得到9个块\n",
    "        \n",
    "        self.value = torch.cat([torch.cat(blocks[i:i+3], dim=2) for i in range(0, 9, 3)], dim=1) # 将9个块按3*3的方式拼成一个大矩阵\n",
    "        self.value = self.value.unsqueeze(1).to(torch.float32)\n",
    "        \n",
    "        self.target = torch.tensor([1.0 if x == 'OK' else 0.0 for x in self.data.iloc[:, 48].values])\n",
    "        self.target = self.target.unsqueeze(1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.value[index], self.target[index]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层\n",
    "        # input:(batch_size, 1, 6, 6), output:(batch_size, 9, 3, 3)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=16*3*3, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0], -1)  # (batch_size, 9*3*3)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)     # (batch_size, 1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "train_dataset = GDdataset(\"./train_data.csv\")\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = GDdataset(\"./test_data.csv\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter   \n",
    "tb = SummaryWriter()\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "\n",
    "# 3. Construct Loss and Optimizer\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 4. define training cycle\n",
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for batch_idx, (value, target) in enumerate(train_loader):\n",
    "        value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + update\n",
    "        output = model(value)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = (output > 0.5).float()\n",
    "        total_correct += (predicted == target).sum().item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        progress = math.ceil(batch_idx / len(train_loader) * 50)\n",
    "        print(\"\\rTrain epoch %d: %d/%d, [%-51s] % d%%\" % (epoch, len(train_dataset), len(train_loader.dataset), '-' * progress + '>', progress * 2), end=\"\")\n",
    "        \n",
    "    # 输出每轮的loss\n",
    "    # print(\"\\n\\n[epoch %d] loss: %.3f train_accuracy: %d / %d=%.3f\" % (epoch+1, running_loss, total_correct, len(train_dataset), total_correct / len(train_dataset)))\n",
    "    \n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)              # scalar标量，即添加一个数字\n",
    "    tb.add_scalar(\"Number Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct / len(train_dataset), epoch)\n",
    "    \n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        correct = 0         # 分类正确个数\n",
    "        # total = 0           # 总数\n",
    "        test_loss = 0\n",
    "        for value, target in test_loader:\n",
    "            value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "            output = model(value)       # (batch_size, 1)\n",
    "            predicted = (output > 0.5).float()\n",
    "            # total += target.size(0)     # 加batch_size\n",
    "            correct += (predicted == target).sum().item()\n",
    "            test_loss += loss_function(output, target).item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        \n",
    "        print(\"\\nTest: average loss: {:.4f}, test_accuracy: {}/{} ({:.0f}%)\".format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        tb.add_scalar(\"Test_accuracy\", correct / len(test_loader.dataset), epoch)\n",
    "        \n",
    "    # print(\"Accuracy on test set: %.1f%%\" % (100 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter conv.0.weight is on device: cuda:0\n",
      "Parameter conv.0.bias is on device: cuda:0\n",
      "Parameter conv.1.weight is on device: cuda:0\n",
      "Parameter conv.1.bias is on device: cuda:0\n",
      "Parameter fc.0.weight is on device: cuda:0\n",
      "Parameter fc.0.bias is on device: cuda:0\n",
      "Parameter fc.2.weight is on device: cuda:0\n",
      "Parameter fc.2.bias is on device: cuda:0\n",
      "Parameter fc.5.weight is on device: cuda:0\n",
      "Parameter fc.5.bias is on device: cuda:0\n",
      "Parameter fc.7.weight is on device: cuda:0\n",
      "Parameter fc.7.bias is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name} is on device: {param.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(50):\n",
    "#     train(model, epoch)\n",
    "#     test(model, epoch)\n",
    "# torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch built-in quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to('cpu')\n",
    "model.load_state_dict(torch.load('model.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "print('Here is the floating point version of this module:')\n",
    "print(model)\n",
    "qmodel = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.Conv2d, nn.Linear, nn.BatchNorm2d, nn.ReLU, nn.Sigmoid}, dtype=torch.qint8\n",
    ")\n",
    "print('and now the quantized version:')\n",
    "print(qmodel)\n",
    "from function import *\n",
    "# compare the sizes\n",
    "f=print_size_of_model(model,\"fp32\")\n",
    "q=print_size_of_model(qmodel,\"int8\")\n",
    "print(\"{0:.2f} times smaller\".format(f/q))\n",
    "# compare the performance\n",
    "print(\"Floating point FP32\")\n",
    "# %timeit test(model, 50)\n",
    "test(model, 10)\n",
    "run_benchmark(model, test_loader)\n",
    "print(\"Quantized INT8\")\n",
    "# %timeit test(qmodel, 10)\n",
    "test(qmodel, 10)\n",
    "run_benchmark(qmodel, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling ...:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling ...:   1%|          | 1/100 [00:00<00:16,  5.89it/s]STAGE:2024-06-07 17:32:45 1751947:1751947 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-06-07 17:32:45 1751947:1751947 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-06-07 17:32:45 1751947:1751947 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "Profiling ...: 100%|██████████| 100/100 [00:00<00:00, 192.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.profiler\n",
    "from tqdm import tqdm\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('model.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "profiler = torch.profiler.profile(\n",
    "    schedule=torch.profiler.schedule(wait=2, warmup=2, active=6, repeat=1),\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(dir_name='./performance/'),\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA\n",
    "    ],\n",
    "    with_stack=True,\n",
    ")\n",
    "profiler.start()\n",
    "with torch.no_grad():\n",
    "    # for value, target in test_loader:\n",
    "    #     value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "    #     output = model(value)       # (batch_size, 1)\n",
    "        # predicted = (output > 0.5).float()\n",
    "        # # total += target.size(0)     # 加batch_size\n",
    "        # correct += (predicted == target).sum().item()\n",
    "        # test_loss += loss_function(output, target).item()\n",
    "    for batch_idx in tqdm(range(100), desc='Profiling ...'):\n",
    "        value, _ = next(iter(train_loader))\n",
    "        model(value.to(device))\n",
    "        profiler.step()\n",
    "profiler.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
