{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to CAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swat\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashost = 'sas-cas-server-default-client'\n",
    "conn = swat.CAS(cashost, 5570, password=os.environ.get('ACCESS_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.about()['About']['Viya Version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.caslibInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.fileInfo(caslib='casuser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.tableInfo(caslib='casuser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the CAS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "castb = conn.CASTable('train_data', caslib='casuser')\n",
    "display(type(castb), castb)     # display type & value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "castb.tableDetails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = castb.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "castb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "castb.columnInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (castb.SFR_Result.value_counts())\n",
    "display(type(df), df)\n",
    "df.plot(kind='bar', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sas.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/sassoftware/python-dlpy.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swat\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import dlpy\n",
    "from dlpy import Sequential\n",
    "from dlpy import *\n",
    "from dlpy.model import TextParms\n",
    "from dlpy.blocks import Bidirectional\n",
    "from dlpy.applications import TextClassification\n",
    "from dlpy.network import *\n",
    "from dlpy.utils import *\n",
    "from dlpy.applications import *\n",
    "from dlpy.model import *\n",
    "from dlpy.images import *\n",
    "from dlpy.layers import *\n",
    "cashost = 'sas-cas-server-default-client'\n",
    "conn = swat.CAS(cashost, 5570, password=os.environ.get('ACCESS_TOKEN'))\n",
    "\n",
    "castb = conn.CASTable('train_data', caslib='casuser')\n",
    "SFR = castb.iloc[:, 2:46].values\n",
    "blocks = [SFR[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] # 将36列中的每4列合并成一个2*2矩阵，得到9个块\n",
    "x_train = np.concatenate([np.concatenate(blocks[i:i+3], axis=2) for i in range(0, 9, 3)], axis=1) # 将9个块按3*3的方式拼成一个大矩阵\n",
    "# 修改train_data\n",
    "# 将 numpy 数组转换为 pandas DataFrame\n",
    "X_train_flat = x_train.reshape(8773, -1)  # 展平图像数据\n",
    "df_train = pd.DataFrame(X_train_flat)\n",
    "df_train['label'] = castb.SFR_Result\n",
    "df_train['label'] = df_train['label'].map({'OK': 1, 'NG': 0})\n",
    "train_data = conn.upload_frame(df_train, casout={'name':'train_data', 'replace':True})\n",
    "\n",
    "# 读取测试数据\n",
    "test_castb = conn.CASTable('test_data', caslib='casuser')\n",
    "\n",
    "# 处理测试数据\n",
    "SFR_test = test_castb.iloc[:, 2:46].values\n",
    "blocks_test = [SFR_test[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] \n",
    "x_test = np.concatenate([np.concatenate(blocks_test[i:i+3], axis=2) for i in range(0, 9, 3)], axis=1)\n",
    "\n",
    "# 将 numpy 数组转换为 pandas DataFrame\n",
    "X_test_flat = x_test.reshape(test_castb.shape[0], -1)  # 展平图像数据\n",
    "df_test = pd.DataFrame(X_test_flat)\n",
    "df_test['label'] = test_castb.SFR_Result\n",
    "df_test['label'] = df_test['label'].map({'OK': 1, 'NG': 0})\n",
    "\n",
    "# 上传测试数据到CAS\n",
    "test_data = conn.upload_frame(df_test, casout={'name': 'test_data', 'replace': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "import types\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import swat\n",
    "import dlpy\n",
    "from dlpy import Sequential\n",
    "from dlpy.model import *\n",
    "from dlpy.layers import *\n",
    "from dlpy.utils import *\n",
    "        \n",
    "# 模型定义和训练\n",
    "model = Sequential(conn, model_table='Simple_CNN')\n",
    "model.add(InputLayer(1, 6, 6))\n",
    "model.add(Conv2d(n_filters=16, width=2, height=2, stride=2, act='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Pooling(1))\n",
    "model.add(Dense(16*3*3, act='relu'))\n",
    "model.add(Dense(256, act='relu'))\n",
    "model.add(Dense(64, act='relu'))\n",
    "model.add(Dense(32, act='relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(OutputLayer(act='sigmoid', n=1))\n",
    "\n",
    "input_vars = train_data.columns[:-1].tolist()  # 除去 'label' 列的所有列名\n",
    "target_var = 'label'\n",
    "model.fit(\n",
    "    data=train_data,\n",
    "    inputs=input_vars,\n",
    "    target=target_var,\n",
    "    mini_batch_size=128,\n",
    "    max_epochs=100,\n",
    "    lr = 0.1,\n",
    "    n_threads=1,\n",
    "    log_level=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "import types\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import swat\n",
    "import dlpy\n",
    "from dlpy import Sequential\n",
    "from dlpy.model import *\n",
    "from dlpy.layers import *\n",
    "from dlpy.utils import *\n",
    "\n",
    "# 创建一个字典来存储调用次数\n",
    "call_count = {}\n",
    "\n",
    "def count_calls(func, module_name=None):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_count_calls(*args, **kwargs):\n",
    "        full_name = module_name + '.' + func.__name__\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        if full_name not in call_count:\n",
    "            call_count[full_name] = {\"count\": 0, \"total_time\": 0.0}\n",
    "        \n",
    "        call_count[full_name][\"count\"] += 1\n",
    "        call_count[full_name][\"total_time\"] += elapsed_time\n",
    "        \n",
    "        return result\n",
    "    wrapper_count_calls._is_decorated = True\n",
    "    return wrapper_count_calls\n",
    "\n",
    "def set_new_attr(module, attr_name, attr):\n",
    "    if not hasattr(attr, \"_is_decorated\"):\n",
    "        decorated_attr = count_calls(attr, module.__name__)\n",
    "        decorated_attr._is_decorated = True\n",
    "        setattr(module, attr_name, decorated_attr)\n",
    "\n",
    "# 递归封装所有的包\n",
    "def auto_decorate_module(module, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    module_name = module.__name__\n",
    "    if module_name in visited:\n",
    "        return\n",
    "    visited.add(module_name)\n",
    "    for attr_name in dir(module):\n",
    "        try:\n",
    "            attr = getattr(module, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "            elif isinstance(attr, types.ModuleType) and attr.__name__.startswith('dlpy'):\n",
    "                auto_decorate_module(attr, visited)\n",
    "            elif isinstance(attr, type):\n",
    "                auto_decorate_class(attr)\n",
    "            elif callable(attr):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "def auto_decorate_class(cls):\n",
    "    for attr_name in dir(cls):\n",
    "        try:\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "            elif attr_name in ['__add__', '__mul__', '__sub__', '__truediv__', '__matmul__', '__pow__', '__mod__']:\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "        except (AttributeError, TypeError):\n",
    "            continue\n",
    "\n",
    "# 自动装饰 dlpy 模块及其子模块\n",
    "auto_decorate_module(dlpy)\n",
    "# 装饰 Layer 类的 __call__ 方法\n",
    "Layer.__call__ = count_calls(Layer.__call__, 'Layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历 test_data 中的64行进行前向计算\n",
    "for index, row in df_test.head(64).iterrows():\n",
    "    # 从 test_data 中获取当前行的前 36 个元素，并将其重塑为 6x6 矩阵\n",
    "    input_data = row.values[:36].reshape((1, 1, 6, 6))\n",
    "    \n",
    "    # 创建输入张量\n",
    "    input_tensor = Tensor(InputLayer(1, 6, 6))\n",
    "    input_tensor.shape = (1, 1, 6, 6)\n",
    "    input_tensor._value = input_data\n",
    "\n",
    "    # 前向计算并记录时间\n",
    "    conv_output = model.layers[1](input_tensor)\n",
    "    batch_norm_output = model.layers[2](conv_output)\n",
    "    pooling_output = model.layers[3](batch_norm_output)\n",
    "    dense_output1 = model.layers[4](pooling_output)\n",
    "    dense_output2 = model.layers[5](dense_output1)\n",
    "    dense_output3 = model.layers[6](dense_output2)\n",
    "    dense_output4 = model.layers[7](dense_output3)\n",
    "    dense_output5 = model.layers[8](dense_output4)\n",
    "    output = model.layers[9](dense_output5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(call_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取预测的浮点数值\n",
    "predicted_probs = pred['P_label'].values\n",
    "\n",
    "# 将预测的浮点数值转换为0或1\n",
    "predicted_labels = np.where(predicted_probs > 0.5, 1.0, 0.0)\n",
    "\n",
    "# 获取实际标签\n",
    "actual_labels = df_test['label'].values\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = np.mean(predicted_labels == actual_labels)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历 test_data 中的每一行进行前向计算\n",
    "for index, row in df_test.iterrows():\n",
    "    # 从 test_data 中获取当前行的前 36 个元素，并将其重塑为 6x6 矩阵\n",
    "    input_data = row.values[:36].reshape((1, 1, 6, 6))\n",
    "    \n",
    "    # 创建输入张量\n",
    "    input_tensor = Tensor(input_layer)\n",
    "    input_tensor.shape = (1, 1, 6, 6)\n",
    "    input_tensor._value = input_data\n",
    "\n",
    "    # 前向计算并记录时间\n",
    "    conv_output = conv_layer(input_tensor)\n",
    "    batch_norm_output = batch_norm_layer(conv_output)\n",
    "    pooling_output = pooling_layer(batch_norm_output)\n",
    "    dense_output1 = dense_layer1(pooling_output)\n",
    "    dense_output2 = dense_layer2(dense_output1)\n",
    "    dense_output3 = dense_layer3(dense_output2)\n",
    "    dense_output4 = dense_layer4(dense_output3)\n",
    "    dense_output5 = dense_layer5(dense_output4)\n",
    "    output = output_layer(dense_output5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历 test_data 中的前 128 行进行前向计算\n",
    "for index, row in df_test.head(128).iterrows():\n",
    "    # 从 test_data 中获取当前行的前 36 个元素，并将其重塑为 6x6 矩阵\n",
    "    input_data = row.values[:36].reshape((1, 1, 6, 6))\n",
    "    \n",
    "    # 创建输入张量\n",
    "    input_tensor = Tensor(input_layer)\n",
    "    input_tensor.shape = (1, 1, 6, 6)\n",
    "    input_tensor._value = input_data\n",
    "\n",
    "    # 前向计算并记录时间\n",
    "    conv_output = conv_layer(input_tensor)\n",
    "    batch_norm_output = batch_norm_layer(conv_output)\n",
    "    pooling_output = pooling_layer(batch_norm_output)\n",
    "    dense_output1 = dense_layer1(pooling_output)\n",
    "    dense_output2 = dense_layer2(dense_output1)\n",
    "    dense_output3 = dense_layer3(dense_output2)\n",
    "    dense_output4 = dense_layer4(dense_output3)\n",
    "    dense_output5 = dense_layer5(dense_output4)\n",
    "    output = output_layer(dense_output5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quant.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim     # for constructing optimizer\n",
    "import torchvision.models as models\n",
    "from module import *\n",
    "from function import *\n",
    "\n",
    "# 1. preparing the dataset\n",
    "class GDdataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.data = pd.read_csv(path)\n",
    "        SFR = torch.tensor(self.data.iloc[:, 2:46].values)\n",
    "        blocks = [SFR[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] # 将36列中的每4列合并成一个2*2矩阵，得到9个块\n",
    "        \n",
    "        self.value = torch.cat([torch.cat(blocks[i:i+3], dim=2) for i in range(0, 9, 3)], dim=1) # 将9个块按3*3的方式拼成一个大矩阵\n",
    "        self.value = self.value.unsqueeze(1).to(torch.float32)\n",
    "        \n",
    "        self.target = torch.tensor([1.0 if x == 'OK' else 0.0 for x in self.data.iloc[:, 48].values])\n",
    "        self.target = self.target.unsqueeze(1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.value[index], self.target[index]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "from module import *\n",
    "# 2. define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(num_features=16)\n",
    "        self.fc1 = nn.Linear(in_features=16*3*3, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc4 = nn.Linear(in_features=32, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 1, 1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        # x = F.dropout(x, p=0.5)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def quantize(self, num_bits=8):\n",
    "        self.qconv = QConvBNReLU(self.conv, self.bn, qi=True, qo=True, num_bits=num_bits)\n",
    "        self.qmaxpool2d = QMaxPooling2d(kernel_size=1)\n",
    "        self.qfc1 = QLinear(self.fc1, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc2 = QLinear(self.fc2, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc3 = QLinear(self.fc3, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc4 = QLinear(self.fc4, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qsigmoid = QSigmoid(qi=False, qo=True, num_bits=num_bits)\n",
    "\n",
    "    def quantize_forward(self, x):\n",
    "        x = self.qconv(x)\n",
    "        x = self.qmaxpool2d(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.qfc1(x)\n",
    "        x = self.qfc2(x)\n",
    "        x = self.qfc3(x)\n",
    "        x = self.qfc4(x)\n",
    "        x = self.qsigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def freeze(self):\n",
    "        self.qconv.freeze()\n",
    "        self.qmaxpool2d.freeze(self.qconv.qo)\n",
    "        self.qfc1.freeze(qi=self.qconv.qo)\n",
    "        self.qfc2.freeze(qi=self.qfc1.qo)\n",
    "        self.qfc3.freeze(qi=self.qfc2.qo)\n",
    "        self.qfc4.freeze(qi=self.qfc3.qo)\n",
    "\n",
    "    def quantize_inference(self, x):\n",
    "        qx = self.qconv.qi.quantize_tensor(x)\n",
    "        qx = self.qconv.quantize_inference(qx)\n",
    "        qx = self.qmaxpool2d.quantize_inference(qx)\n",
    "        qx = qx.view(qx.shape[0], -1)\n",
    "        qx = self.qfc1.quantize_inference(qx)\n",
    "        qx = self.qfc2.quantize_inference(qx)\n",
    "        qx = self.qfc3.quantize_inference(qx)\n",
    "        qx = self.qfc4.quantize_inference(qx)\n",
    "        \n",
    "        out = self.qfc4.qo.dequantize_tensor(qx)\n",
    "        return out\n",
    "    \n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = GDdataset(\"./train_data.csv\")\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = GDdataset(\"./test_data.csv\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model):   # 全精度推理\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0         # 分类正确个数\n",
    "        test_loss = 0\n",
    "        for value, target in test_loader:\n",
    "            value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "            output = model(value)       # (batch_size, 1)\n",
    "            predicted = (output > 0.5).float()\n",
    "            correct += (predicted == target).sum().item()\n",
    "            test_loss += loss_function(output, target).item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        \n",
    "    print(\"\\nTest: average loss: {:.4f}, test_accuracy: {}/{} ({:.0f}%)\".format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def qinference(model):  # 量化推理\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        correct = 0         # 分类正确个数\n",
    "        test_loss = 0\n",
    "        for value, target in test_loader:\n",
    "            value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "            output = model.quantize_inference(value)       # (batch_size, 1)\n",
    "            predicted = (output > 0.5).float()\n",
    "            correct += (predicted == target).sum().item()\n",
    "    print(\"\\ntest_accuracy: {}/{} ({:.0f}%)\".format(correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "            \n",
    "    \n",
    "def direct_quantize(model, test_loader):\n",
    "    for i, (value, target) in enumerate(test_loader, 1):\n",
    "        value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "        output = model.quantize_forward(value)\n",
    "        if i % 500 == 0:\n",
    "            break\n",
    "    print('direct quantization finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct quantization finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaozhe/anaconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import types\n",
    "import time\n",
    "import pprint\n",
    "# 创建一个字典来存储调用次数\n",
    "call_count = {}\n",
    "\n",
    "def count_calls(func, module_name=None):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_count_calls(*args, **kwargs):\n",
    "        # module_name = func.__module__ if hasattr(func, '__module__') and func.__module__ else 'torch'\n",
    "        full_name = module_name + '.' + func.__name__\n",
    "        # call_count[full_name] = call_count.get(full_name, 0) + 1\n",
    "        # print(f\"Function {full_name} called {call_count[full_name]} times\")\n",
    "        # return func(*args, **kwargs)\n",
    "        # 记录开始时间\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        # 记录结束时间\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # 计算调用时间\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        if full_name not in call_count:\n",
    "            call_count[full_name] = {\"count\": 0, \"total_time\": 0.0}\n",
    "        \n",
    "        call_count[full_name][\"count\"] += 1\n",
    "        call_count[full_name][\"total_time\"] += elapsed_time\n",
    "        \n",
    "        return result\n",
    "    wrapper_count_calls._is_decorated = True\n",
    "    return wrapper_count_calls\n",
    "\n",
    "def set_new_attr(module, attr_name, attr):\n",
    "    if not hasattr(attr, \"_is_decorated\"):\n",
    "        decorated_attr = count_calls(attr, module.__name__)\n",
    "        decorated_attr._is_decorated = True\n",
    "        setattr(module, attr_name, decorated_attr)\n",
    "\n",
    "# 递归封装所有的包\n",
    "def auto_decorate_module(module, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    module_name = module.__name__\n",
    "    if module_name in visited:\n",
    "        return\n",
    "    visited.add(module_name)\n",
    "    for attr_name in dir(module):\n",
    "        try:\n",
    "            attr = getattr(module, attr_name)\n",
    "            # if isinstance(attr, types.FunctionType):\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "                # print(f\"Decorated function: {module_name}.{attr_name}\")\n",
    "            elif isinstance(attr, types.ModuleType) and attr.__name__.startswith('torch'):\n",
    "                # print(f\"Descending into module: {attr.__name__}\")\n",
    "                auto_decorate_module(attr, visited)\n",
    "            elif isinstance(attr, type):\n",
    "                # print(f\"Descending into class: {attr.__name__} in {module_name}\")\n",
    "                auto_decorate_class(attr)\n",
    "            elif callable(attr):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "\n",
    "def auto_decorate_class(cls):\n",
    "    for attr_name in dir(cls):\n",
    "        # if attr_name.startswith('__') and attr_name.endswith('__'):\n",
    "        #     continue  # Skip special attributes\n",
    "        try:\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "            elif attr_name in ['__add__', '__mul__', '__sub__', '__truediv__', '__matmul__', '__pow__', '__mod__']:\n",
    "                # 特殊处理运算符重载方法\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "        except (AttributeError, TypeError) as e:\n",
    "            continue\n",
    "            \n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('qmodel.pt', map_location='cpu'))sas\n",
    "model.eval()\n",
    "num_bits = 4\n",
    "model.quantize(num_bits=num_bits)\n",
    "direct_quantize(model, train_loader)\n",
    "model.freeze()\n",
    "value, _ = next(iter(test_loader))\n",
    "value = value.to(device)\n",
    "auto_decorate_module(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.quantize_inference(value)\n",
    "pprint.pprint(call_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim     # for constructing optimizer\n",
    "import torchvision.models as models\n",
    "from module import *\n",
    "from function import *\n",
    "\n",
    "# 1. preparing the dataset\n",
    "class GDdataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.data = pd.read_csv(path)\n",
    "        SFR = torch.tensor(self.data.iloc[:, 2:46].values)\n",
    "        blocks = [SFR[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] # 将36列中的每4列合并成一个2*2矩阵，得到9个块\n",
    "        \n",
    "        self.value = torch.cat([torch.cat(blocks[i:i+3], dim=2) for i in range(0, 9, 3)], dim=1) # 将9个块按3*3的方式拼成一个大矩阵\n",
    "        self.value = self.value.unsqueeze(1).to(torch.float32)\n",
    "        \n",
    "        self.target = torch.tensor([1.0 if x == 'OK' else 0.0 for x in self.data.iloc[:, 48].values])\n",
    "        self.target = self.target.unsqueeze(1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.value[index], self.target[index]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "from module import *\n",
    "# 2. define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(num_features=16)\n",
    "        self.fc1 = nn.Linear(in_features=16*3*3, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc4 = nn.Linear(in_features=32, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 1, 1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        # x = F.dropout(x, p=0.5)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def quantize(self, num_bits=8):\n",
    "        self.qconv = QConvBNReLU(self.conv, self.bn, qi=True, qo=True, num_bits=num_bits)\n",
    "        self.qmaxpool2d = QMaxPooling2d(kernel_size=1)\n",
    "        self.qfc1 = QLinear(self.fc1, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc2 = QLinear(self.fc2, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc3 = QLinear(self.fc3, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc4 = QLinear(self.fc4, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qsigmoid = QSigmoid(qi=False, qo=True, num_bits=num_bits)\n",
    "\n",
    "    def quantize_forward(self, x):\n",
    "        x = self.qconv(x)\n",
    "        x = self.qmaxpool2d(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.qfc1(x)\n",
    "        x = self.qfc2(x)\n",
    "        x = self.qfc3(x)\n",
    "        x = self.qfc4(x)\n",
    "        x = self.qsigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def freeze(self):\n",
    "        self.qconv.freeze()\n",
    "        self.qmaxpool2d.freeze(self.qconv.qo)\n",
    "        self.qfc1.freeze(qi=self.qconv.qo)\n",
    "        self.qfc2.freeze(qi=self.qfc1.qo)\n",
    "        self.qfc3.freeze(qi=self.qfc2.qo)\n",
    "        self.qfc4.freeze(qi=self.qfc3.qo)\n",
    "\n",
    "    def quantize_inference(self, x):\n",
    "        qx = self.qconv.qi.quantize_tensor(x)\n",
    "        qx = self.qconv.quantize_inference(qx)\n",
    "        qx = self.qmaxpool2d.quantize_inference(qx)\n",
    "        qx = qx.view(qx.shape[0], -1)\n",
    "        qx = self.qfc1.quantize_inference(qx)\n",
    "        qx = self.qfc2.quantize_inference(qx)\n",
    "        qx = self.qfc3.quantize_inference(qx)\n",
    "        qx = self.qfc4.quantize_inference(qx)\n",
    "        \n",
    "        out = self.qfc4.qo.dequantize_tensor(qx)\n",
    "        return out\n",
    "    \n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = GDdataset(\"./train_data.csv\")\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = GDdataset(\"./test_data.csv\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 144])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4950],\n",
       "        [0.4941],\n",
       "        [0.4928],\n",
       "        [0.4835],\n",
       "        [0.4927],\n",
       "        [0.4919],\n",
       "        [0.4939],\n",
       "        [0.4883],\n",
       "        [0.4921],\n",
       "        [0.4839],\n",
       "        [0.4934],\n",
       "        [0.4975],\n",
       "        [0.4917],\n",
       "        [0.4992],\n",
       "        [0.4958],\n",
       "        [0.4949],\n",
       "        [0.4932],\n",
       "        [0.4919],\n",
       "        [0.4951],\n",
       "        [0.4915],\n",
       "        [0.4923],\n",
       "        [0.4952],\n",
       "        [0.4876],\n",
       "        [0.4935],\n",
       "        [0.4937],\n",
       "        [0.4928],\n",
       "        [0.4855],\n",
       "        [0.4946],\n",
       "        [0.4960],\n",
       "        [0.4909],\n",
       "        [0.4970],\n",
       "        [0.4928],\n",
       "        [0.4920],\n",
       "        [0.4900],\n",
       "        [0.4851],\n",
       "        [0.4882],\n",
       "        [0.4925],\n",
       "        [0.4935],\n",
       "        [0.4934],\n",
       "        [0.4925],\n",
       "        [0.4921],\n",
       "        [0.4928],\n",
       "        [0.4987],\n",
       "        [0.4938],\n",
       "        [0.4947],\n",
       "        [0.4942],\n",
       "        [0.4930],\n",
       "        [0.4925],\n",
       "        [0.4885],\n",
       "        [0.4926],\n",
       "        [0.4867],\n",
       "        [0.4893],\n",
       "        [0.4892],\n",
       "        [0.4945],\n",
       "        [0.4915],\n",
       "        [0.4886],\n",
       "        [0.4958],\n",
       "        [0.4936],\n",
       "        [0.4972],\n",
       "        [0.4955],\n",
       "        [0.4917],\n",
       "        [0.4982],\n",
       "        [0.4973],\n",
       "        [0.4932],\n",
       "        [0.4899],\n",
       "        [0.4882],\n",
       "        [0.4931],\n",
       "        [0.4948],\n",
       "        [0.4933],\n",
       "        [0.4951],\n",
       "        [0.4926],\n",
       "        [0.4917],\n",
       "        [0.4934],\n",
       "        [0.4946],\n",
       "        [0.4863],\n",
       "        [0.4901],\n",
       "        [0.4962],\n",
       "        [0.4963],\n",
       "        [0.4834],\n",
       "        [0.4867],\n",
       "        [0.4909],\n",
       "        [0.4904],\n",
       "        [0.4917],\n",
       "        [0.4957],\n",
       "        [0.4884],\n",
       "        [0.4911],\n",
       "        [0.4921],\n",
       "        [0.4888],\n",
       "        [0.4933],\n",
       "        [0.4940],\n",
       "        [0.4956],\n",
       "        [0.4902],\n",
       "        [0.4927],\n",
       "        [0.4945],\n",
       "        [0.4980],\n",
       "        [0.4928],\n",
       "        [0.4907],\n",
       "        [0.4960],\n",
       "        [0.4940],\n",
       "        [0.4889],\n",
       "        [0.4955],\n",
       "        [0.4928],\n",
       "        [0.4968],\n",
       "        [0.4961],\n",
       "        [0.4907],\n",
       "        [0.4877],\n",
       "        [0.4959],\n",
       "        [0.4946],\n",
       "        [0.4918],\n",
       "        [0.4906],\n",
       "        [0.4933],\n",
       "        [0.4956],\n",
       "        [0.4928],\n",
       "        [0.4896],\n",
       "        [0.4962],\n",
       "        [0.4902],\n",
       "        [0.4925],\n",
       "        [0.4910],\n",
       "        [0.4888],\n",
       "        [0.4919],\n",
       "        [0.4913],\n",
       "        [0.4972],\n",
       "        [0.4936],\n",
       "        [0.4920],\n",
       "        [0.4976],\n",
       "        [0.4901],\n",
       "        [0.4887],\n",
       "        [0.4980]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "value, _ = next(iter(test_loader))\n",
    "model(value.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import types\n",
    "import time\n",
    "import pprint\n",
    "# 创建一个字典来存储调用次数\n",
    "call_count = {}\n",
    "\n",
    "def count_calls(func, module_name=None):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_count_calls(*args, **kwargs):\n",
    "        # module_name = func.__module__ if hasattr(func, '__module__') and func.__module__ else 'torch'\n",
    "        full_name = module_name + '.' + func.__name__\n",
    "        # call_count[full_name] = call_count.get(full_name, 0) + 1\n",
    "        # print(f\"Function {full_name} called {call_count[full_name]} times\")\n",
    "        # return func(*args, **kwargs)\n",
    "        # 记录开始时间\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        # 记录结束时间\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # 计算调用时间\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        if full_name not in call_count:\n",
    "            call_count[full_name] = {\"count\": 0, \"total_time\": 0.0}\n",
    "        \n",
    "        call_count[full_name][\"count\"] += 1\n",
    "        call_count[full_name][\"total_time\"] += elapsed_time\n",
    "        \n",
    "        return result\n",
    "    wrapper_count_calls._is_decorated = True\n",
    "    return wrapper_count_calls\n",
    "\n",
    "def set_new_attr(module, attr_name, attr):\n",
    "    if not hasattr(attr, \"_is_decorated\"):\n",
    "        decorated_attr = count_calls(attr, module.__name__)\n",
    "        decorated_attr._is_decorated = True\n",
    "        setattr(module, attr_name, decorated_attr)\n",
    "\n",
    "# 递归封装所有的包\n",
    "def auto_decorate_module(module, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    module_name = module.__name__\n",
    "    if module_name in visited:\n",
    "        return\n",
    "    visited.add(module_name)\n",
    "    for attr_name in dir(module):\n",
    "        try:\n",
    "            attr = getattr(module, attr_name)\n",
    "            # if isinstance(attr, types.FunctionType):\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "                # print(f\"Decorated function: {module_name}.{attr_name}\")\n",
    "            elif isinstance(attr, types.ModuleType) and attr.__name__.startswith('torch'):\n",
    "                # print(f\"Descending into module: {attr.__name__}\")\n",
    "                auto_decorate_module(attr, visited)\n",
    "            elif isinstance(attr, type):\n",
    "                # print(f\"Descending into class: {attr.__name__} in {module_name}\")\n",
    "                auto_decorate_class(attr)\n",
    "            elif callable(attr):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "\n",
    "def auto_decorate_class(cls):\n",
    "    for attr_name in dir(cls):\n",
    "        # if attr_name.startswith('__') and attr_name.endswith('__'):\n",
    "        #     continue  # Skip special attributes\n",
    "        try:\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "            elif attr_name in ['__add__', '__mul__', '__sub__', '__truediv__', '__matmul__', '__pow__', '__mod__']:\n",
    "                # 特殊处理运算符重载方法\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "        except (AttributeError, TypeError) as e:\n",
    "            continue\n",
    "            \n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('model.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "value, _ = next(iter(test_loader))\n",
    "\n",
    "auto_decorate_module(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(value)\n",
    "pprint.pprint(call_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'ABCMeta.__instancecheck__': {'count': 11,\n",
    "                               'total_time': 2.1457672119140625e-05},\n",
    " 'BatchNorm2d.__getattr__': {'count': 5, 'total_time': 4.5299530029296875e-06},\n",
    " 'BatchNorm2d._call_impl': {'count': 1, 'total_time': 0.00021457672119140625},\n",
    " 'BatchNorm2d._check_input_dim': {'count': 1,\n",
    "                                  'total_time': 4.291534423828125e-06},\n",
    " 'BatchNorm2d._wrapped_call_impl': {'count': 1,\n",
    "                                    'total_time': 0.00021958351135253906},\n",
    " 'BatchNorm2d.forward': {'count': 1, 'total_time': 0.00020074844360351562},\n",
    " 'ContextProp.__get__': {'count': 1, 'total_time': 4.76837158203125e-06},\n",
    " 'Conv2d.__getattr__': {'count': 2, 'total_time': 1.6689300537109375e-06},\n",
    " 'Conv2d._call_impl': {'count': 1, 'total_time': 0.0011267662048339844},\n",
    " 'Conv2d._conv_forward': {'count': 1, 'total_time': 0.0011107921600341797},\n",
    " 'Conv2d._wrapped_call_impl': {'count': 1, 'total_time': 0.0011310577392578125},\n",
    " 'Conv2d.forward': {'count': 1, 'total_time': 0.0011196136474609375},\n",
    " 'FunctionMeta.__getattribute__': {'count': 694,\n",
    "                                   'total_time': 0.0006601810455322266},\n",
    " 'FunctionMeta.__setattr__': {'count': 17,\n",
    "                              'total_time': 1.5020370483398438e-05},\n",
    " 'Linear.__getattr__': {'count': 8, 'total_time': 6.9141387939453125e-06},\n",
    " 'Linear._call_impl': {'count': 4, 'total_time': 0.0005695819854736328},\n",
    " 'Linear._wrapped_call_impl': {'count': 4, 'total_time': 0.0005776882171630859},\n",
    " 'Linear.forward': {'count': 4, 'total_time': 0.00054168701171875},\n",
    " 'Mapping.get': {'count': 2, 'total_time': 1.621246337890625e-05},\n",
    " 'Module.__getattr__': {'count': 7, 'total_time': 1.2159347534179688e-05},\n",
    " 'Module._call_impl': {'count': 2, 'total_time': 0.0024499893188476562},\n",
    " 'Module._wrapped_call_impl': {'count': 2, 'total_time': 0.002457857131958008},\n",
    " 'OpOverloadPacket.__getattr__': {'count': 1031,\n",
    "                                  'total_time': 0.0009160041809082031},\n",
    " 'OpOverloadPacket.__str__': {'count': 2062,\n",
    "                              'total_time': 0.0016379356384277344},\n",
    " 'Queue._get': {'count': 3, 'total_time': 2.384185791015625e-06},\n",
    " 'Queue._put': {'count': 3, 'total_time': 2.384185791015625e-06},\n",
    " 'Queue._qsize': {'count': 78, 'total_time': 3.0040740966796875e-05},\n",
    " 'Queue.empty': {'count': 75, 'total_time': 0.00018930435180664062},\n",
    " 'Queue.get': {'count': 3, 'total_time': 1.6450881958007812e-05},\n",
    " 'Queue.put': {'count': 3, 'total_time': 2.4318695068359375e-05},\n",
    " 'Sigmoid.forward': {'count': 1, 'total_time': 6.079673767089844e-05},\n",
    " 'Tensor.__format__': {'count': 64, 'total_time': 0.0001811981201171875},\n",
    " 'Tensor.__iter__': {'count': 2, 'total_time': 0.00019240379333496094},\n",
    " 'Tensor.__repr__': {'count': 1, 'total_time': 0.0019884109497070312},\n",
    " 'Tensor.__truediv__': {'count': 1, 'total_time': 3.6716461181640625e-05},\n",
    " 'UnpackedDualTensor.__new__': {'count': 1,\n",
    "                                'total_time': 1.430511474609375e-06},\n",
    " '_ClassPropertyDescriptor.__get__': {'count': 36,\n",
    "                                      'total_time': 6.818771362304688e-05},\n",
    " '_Formatter.__init__': {'count': 1, 'total_time': 0.0010960102081298828},\n",
    " '_Formatter.format': {'count': 64, 'total_time': 9.608268737792969e-05},\n",
    " '_Formatter.width': {'count': 64, 'total_time': 1.3828277587890625e-05},\n",
    " '_GenericAlias.__getattr__': {'count': 14,\n",
    "                               'total_time': 6.4373016357421875e-06},\n",
    " '_GenericAlias.__hash__': {'count': 70, 'total_time': 6.008148193359375e-05},\n",
    " '_ModeStackStateForPreDispatch.count': {'count': 1,\n",
    "                                         'total_time': 1.9073486328125e-06},\n",
    " '_NoParamDecoratorContextManager.__new__': {'count': 2,\n",
    "                                             'total_time': 3.0994415283203125e-06},\n",
    " '_ParameterMeta.__instancecheck__': {'count': 1,\n",
    "                                      'total_time': 3.0994415283203125e-06},\n",
    " '_lazy_property_and_property.__init__': {'count': 8,\n",
    "                                          'total_time': 5.0067901611328125e-06},\n",
    " '_reduce_op.__getattribute__': {'count': 6, 'total_time': 0.00070953369140625},\n",
    " 'cached_property.__get__': {'count': 13, 'total_time': 6.198883056640625e-06},\n",
    " 'lazy_property.__get__': {'count': 64, 'total_time': 5.3882598876953125e-05},\n",
    " 'no_grad.__enter__': {'count': 2, 'total_time': 2.3365020751953125e-05},\n",
    " 'no_grad.__exit__': {'count': 2, 'total_time': 1.2874603271484375e-05},\n",
    " 'no_grad.__init__': {'count': 2, 'total_time': 9.5367431640625e-06},\n",
    " 'set_grad_enabled.__init__': {'count': 4, 'total_time': 2.002716064453125e-05},\n",
    " 'torch._C._functorch.is_functorch_wrapped_tensor': {'count': 1,\n",
    "                                                     'total_time': 2.6226043701171875e-06},\n",
    " 'torch._C._get_default_device': {'count': 1,\n",
    "                                  'total_time': 1.6689300537109375e-06},\n",
    " 'torch._C._get_tracing_state': {'count': 10,\n",
    "                                 'total_time': 2.2172927856445312e-05},\n",
    " 'torch._C._set_grad_enabled': {'count': 4,\n",
    "                                'total_time': 4.5299530029296875e-06},\n",
    " 'torch._is_functional_tensor': {'count': 1, 'total_time': 5.7220458984375e-06},\n",
    " 'torch._jit_internal.is_scripting': {'count': 2,\n",
    "                                      'total_time': 1.430511474609375e-06},\n",
    " 'torch._ops._len_torch_dispatch_stack_pre_dispatch': {'count': 1,\n",
    "                                                       'total_time': 8.106231689453125e-06},\n",
    " 'torch._ops.mode_stack_state_for_pre_dispatch': {'count': 1,\n",
    "                                                  'total_time': 9.5367431640625e-07},\n",
    " 'torch._tensor._has_torch_function_unary': {'count': 65,\n",
    "                                             'total_time': 1.5974044799804688e-05},\n",
    " 'torch._tensor_str._add_suffixes': {'count': 1,\n",
    "                                     'total_time': 3.5762786865234375e-06},\n",
    " 'torch._tensor_str._str': {'count': 1, 'total_time': 0.0019779205322265625},\n",
    " 'torch._tensor_str._str_intern': {'count': 1,\n",
    "                                   'total_time': 0.0018842220306396484},\n",
    " 'torch._tensor_str._tensor_str': {'count': 1,\n",
    "                                   'total_time': 0.001772165298461914},\n",
    " 'torch._tensor_str._tensor_str_with_formatter': {'count': 65,\n",
    "                                                  'total_time': 0.0011162757873535156},\n",
    " 'torch._tensor_str._vector_str': {'count': 64,\n",
    "                                   'total_time': 0.00038051605224609375},\n",
    " 'torch._tensor_str.tensor_totype': {'count': 3,\n",
    "                                     'total_time': 1.9073486328125e-05},\n",
    " 'torch.autograd.forward_ad.unpack_dual': {'count': 1,\n",
    "                                           'total_time': 5.4836273193359375e-06},\n",
    " 'torch.autograd.function._warn_traceable_deprecated': {'count': 6,\n",
    "                                                        'total_time': 0.0002455711364746094},\n",
    " 'torch.batch_norm': {'count': 1, 'total_time': 0.00015163421630859375},\n",
    " 'torch.ceil': {'count': 1, 'total_time': 2.9325485229492188e-05},\n",
    " 'torch.get_default_dtype': {'count': 2, 'total_time': 1.430511474609375e-06},\n",
    " 'torch.is_grad_enabled': {'count': 6, 'total_time': 2.384185791015625e-06},\n",
    " 'torch.isfinite': {'count': 1, 'total_time': 0.0001468658447265625},\n",
    " 'torch.masked_select': {'count': 1, 'total_time': 9.846687316894531e-05},\n",
    " 'torch.max_pool2d': {'count': 1, 'total_time': 0.00012755393981933594},\n",
    " 'torch.nn.functional._has_torch_function_unary': {'count': 5,\n",
    "                                                   'total_time': 1.9073486328125e-06},\n",
    " 'torch.nn.functional._has_torch_function_variadic': {'count': 1,\n",
    "                                                      'total_time': 7.152557373046875e-07},\n",
    " 'torch.nn.functional.batch_norm': {'count': 1,\n",
    "                                    'total_time': 0.0001735687255859375},\n",
    " 'torch.nn.functional.conv2d': {'count': 1,\n",
    "                                'total_time': 0.0010974407196044922},\n",
    " 'torch.nn.functional.linear': {'count': 4,\n",
    "                                'total_time': 0.0005085468292236328},\n",
    " 'torch.nn.functional.max_pool2d': {'count': 1,\n",
    "                                    'total_time': 0.00013709068298339844},\n",
    " 'torch.nn.functional.relu': {'count': 4, 'total_time': 0.0001201629638671875},\n",
    " 'torch.relu': {'count': 4, 'total_time': 0.00010156631469726562},\n",
    " 'torch.sigmoid': {'count': 1, 'total_time': 5.650520324707031e-05},\n",
    " 'torch.utils._python_dispatch._disable_current_modes': {'count': 1,\n",
    "                                                         'total_time': 3.337860107421875e-06},\n",
    " 'torch.utils._python_dispatch._len_torch_dispatch_stack': {'count': 1,\n",
    "                                                            'total_time': 7.152557373046875e-07}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'BN.__call__': {'count': 64, 'total_time': 0.0003211498260498047},\n",
    " 'BN._assert_inputs': {'count': 64, 'total_time': 1.8596649169921875e-05},\n",
    " 'Conv2d.__call__': {'count': 64, 'total_time': 0.0007078647613525391},\n",
    " 'Conv2d._assert_inputs': {'count': 64, 'total_time': 2.2172927856445312e-05},\n",
    " 'Dense.__call__': {'count': 320, 'total_time': 0.0014071464538574219},\n",
    " 'Dense._assert_inputs': {'count': 320, 'total_time': 7.319450378417969e-05},\n",
    " 'InputLayer.__init__': {'count': 64, 'total_time': 0.0007097721099853516},\n",
    " 'Layer.__call__': {'count': 256, 'total_time': 0.0012547969818115234},\n",
    " 'Layer.__init__': {'count': 64, 'total_time': 7.200241088867188e-05},\n",
    " 'Layer._assert_inputs': {'count': 128, 'total_time': 3.0517578125e-05},\n",
    " 'Node.__init__': {'count': 576, 'total_time': 0.00013875961303710938},\n",
    " 'Tensor.__init__': {'count': 704, 'total_time': 0.00018477439880371094},\n",
    " 'dlpy.layers._unpack_config': {'count': 64,\n",
    "                                'total_time': 0.00021314620971679688},\n",
    " 'dlpy.layers.get_color': {'count': 64, 'total_time': 5.412101745605469e-05}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'ABCMeta.__instancecheck__': {'count': 23,\n",
    "                               'total_time': 0.00011324882507324219},\n",
    " 'ABCMeta.__subclasscheck__': {'count': 31,\n",
    "                               'total_time': 0.00019693374633789062},\n",
    " 'Conv2d.__getattr__': {'count': 2, 'total_time': 1.430511474609375e-06},\n",
    " 'Conv2d._call_impl': {'count': 1, 'total_time': 0.0004940032958984375},\n",
    " 'Conv2d._conv_forward': {'count': 1, 'total_time': 0.00046372413635253906},\n",
    " 'Conv2d._wrapped_call_impl': {'count': 1, 'total_time': 0.0004985332489013672},\n",
    " 'Conv2d.forward': {'count': 1, 'total_time': 0.0004734992980957031},\n",
    " 'FunctionMeta.__getattribute__': {'count': 694,\n",
    "                                   'total_time': 0.0006117820739746094},\n",
    " 'FunctionMeta.__setattr__': {'count': 17,\n",
    "                              'total_time': 1.3828277587890625e-05},\n",
    " 'Linear.__getattr__': {'count': 8, 'total_time': 6.4373016357421875e-06},\n",
    " 'Linear._call_impl': {'count': 4, 'total_time': 0.00022482872009277344},\n",
    " 'Linear._wrapped_call_impl': {'count': 4,\n",
    "                               'total_time': 0.00023365020751953125},\n",
    " 'Linear.forward': {'count': 4, 'total_time': 0.0001964569091796875},\n",
    " 'Mapping.get': {'count': 2, 'total_time': 1.6450881958007812e-05},\n",
    " 'Module.__getattr__': {'count': 44, 'total_time': 5.269050598144531e-05},\n",
    " 'OpOverloadPacket.__getattr__': {'count': 1031,\n",
    "                                  'total_time': 0.0009312629699707031},\n",
    " 'OpOverloadPacket.__str__': {'count': 2062, 'total_time': 0.09182119369506836},\n",
    " 'Queue._get': {'count': 4, 'total_time': 2.384185791015625e-06},\n",
    " 'Queue._put': {'count': 4, 'total_time': 3.337860107421875e-06},\n",
    " 'Queue._qsize': {'count': 129, 'total_time': 4.601478576660156e-05},\n",
    " 'Queue.empty': {'count': 125, 'total_time': 0.00028228759765625},\n",
    " 'Queue.get': {'count': 4, 'total_time': 2.1696090698242188e-05},\n",
    " 'Queue.put': {'count': 4, 'total_time': 2.956390380859375e-05},\n",
    " 'Tensor.__add__': {'count': 6, 'total_time': 6.175041198730469e-05},\n",
    " 'Tensor.__format__': {'count': 64, 'total_time': 0.0001678466796875},\n",
    " 'Tensor.__iter__': {'count': 2, 'total_time': 0.00019860267639160156},\n",
    " 'Tensor.__mul__': {'count': 6, 'total_time': 6.914138793945312e-05},\n",
    " 'Tensor.__repr__': {'count': 1, 'total_time': 0.001844167709350586},\n",
    " 'Tensor.__sub__': {'count': 6, 'total_time': 5.7220458984375e-05},\n",
    " 'Tensor.__truediv__': {'count': 2, 'total_time': 0.00017309188842773438},\n",
    " 'UnpackedDualTensor.__new__': {'count': 1,\n",
    "                                'total_time': 1.430511474609375e-06},\n",
    " '_ClassPropertyDescriptor.__get__': {'count': 36,\n",
    "                                      'total_time': 6.341934204101562e-05},\n",
    " '_Formatter.__init__': {'count': 1, 'total_time': 0.0009264945983886719},\n",
    " '_Formatter.format': {'count': 64, 'total_time': 7.081031799316406e-05},\n",
    " '_Formatter.width': {'count': 64, 'total_time': 1.7642974853515625e-05},\n",
    " '_GenericAlias.__getattr__': {'count': 14,\n",
    "                               'total_time': 6.4373016357421875e-06},\n",
    " '_GenericAlias.__hash__': {'count': 112, 'total_time': 5.698204040527344e-05},\n",
    " '_ModeStackStateForPreDispatch.count': {'count': 1,\n",
    "                                         'total_time': 2.1457672119140625e-06},\n",
    " '_NoParamDecoratorContextManager.__new__': {'count': 2,\n",
    "                                             'total_time': 2.6226043701171875e-06},\n",
    " '_ParameterMeta.__instancecheck__': {'count': 1,\n",
    "                                      'total_time': 3.337860107421875e-06},\n",
    " '_lazy_property_and_property.__init__': {'count': 8,\n",
    "                                          'total_time': 3.337860107421875e-06},\n",
    " '_reduce_op.__getattribute__': {'count': 6,\n",
    "                                 'total_time': 0.0006513595581054688},\n",
    " 'cached_property.__get__': {'count': 13, 'total_time': 8.106231689453125e-06},\n",
    " 'lazy_property.__get__': {'count': 64, 'total_time': 4.673004150390625e-05},\n",
    " 'no_grad.__enter__': {'count': 2, 'total_time': 2.384185791015625e-05},\n",
    " 'no_grad.__exit__': {'count': 2, 'total_time': 1.239776611328125e-05},\n",
    " 'no_grad.__init__': {'count': 2, 'total_time': 9.775161743164062e-06},\n",
    " 'set_grad_enabled.__init__': {'count': 4,\n",
    "                               'total_time': 2.1457672119140625e-05},\n",
    " 'torch._C._functorch.is_functorch_wrapped_tensor': {'count': 1,\n",
    "                                                     'total_time': 2.86102294921875e-06},\n",
    " 'torch._C._get_default_device': {'count': 1,\n",
    "                                  'total_time': 1.9073486328125e-06},\n",
    " 'torch._C._get_tracing_state': {'count': 7,\n",
    "                                 'total_time': 1.5735626220703125e-05},\n",
    " 'torch._C._set_grad_enabled': {'count': 4,\n",
    "                                'total_time': 5.245208740234375e-06},\n",
    " 'torch._is_functional_tensor': {'count': 1,\n",
    "                                 'total_time': 9.775161743164062e-06},\n",
    " 'torch._jit_internal.is_scripting': {'count': 2,\n",
    "                                      'total_time': 1.430511474609375e-06},\n",
    " 'torch._ops._len_torch_dispatch_stack_pre_dispatch': {'count': 1,\n",
    "                                                       'total_time': 8.106231689453125e-06},\n",
    " 'torch._ops.mode_stack_state_for_pre_dispatch': {'count': 1,\n",
    "                                                  'total_time': 9.5367431640625e-07},\n",
    " 'torch._tensor._has_torch_function_unary': {'count': 65,\n",
    "                                             'total_time': 1.7404556274414062e-05},\n",
    " 'torch._tensor_str._add_suffixes': {'count': 1,\n",
    "                                     'total_time': 4.0531158447265625e-06},\n",
    " 'torch._tensor_str._str': {'count': 1, 'total_time': 0.0018336772918701172},\n",
    " 'torch._tensor_str._str_intern': {'count': 1,\n",
    "                                   'total_time': 0.0017368793487548828},\n",
    " 'torch._tensor_str._tensor_str': {'count': 1,\n",
    "                                   'total_time': 0.001621246337890625},\n",
    " 'torch._tensor_str._tensor_str_with_formatter': {'count': 65,\n",
    "                                                  'total_time': 0.0011370182037353516},\n",
    " 'torch._tensor_str._vector_str': {'count': 64,\n",
    "                                   'total_time': 0.00037741661071777344},\n",
    " 'torch._tensor_str.tensor_totype': {'count': 3,\n",
    "                                     'total_time': 1.7642974853515625e-05},\n",
    " 'torch.autograd.forward_ad.unpack_dual': {'count': 1,\n",
    "                                           'total_time': 4.76837158203125e-06},\n",
    " 'torch.autograd.function._warn_traceable_deprecated': {'count': 6,\n",
    "                                                        'total_time': 0.0002243518829345703},\n",
    " 'torch.ceil': {'count': 1, 'total_time': 2.3126602172851562e-05},\n",
    " 'torch.get_default_dtype': {'count': 2, 'total_time': 1.6689300537109375e-06},\n",
    " 'torch.is_grad_enabled': {'count': 6, 'total_time': 2.86102294921875e-06},\n",
    " 'torch.isfinite': {'count': 1, 'total_time': 0.00011134147644042969},\n",
    " 'torch.masked_select': {'count': 1, 'total_time': 8.20159912109375e-05},\n",
    " 'torch.max_pool2d': {'count': 1, 'total_time': 3.910064697265625e-05},\n",
    " 'torch.nn.functional._has_torch_function_unary': {'count': 1,\n",
    "                                                   'total_time': 4.76837158203125e-07},\n",
    " 'torch.nn.functional.conv2d': {'count': 1,\n",
    "                                'total_time': 0.00045418739318847656},\n",
    " 'torch.nn.functional.linear': {'count': 4,\n",
    "                                'total_time': 0.00016880035400390625},\n",
    " 'torch.nn.functional.max_pool2d': {'count': 1,\n",
    "                                    'total_time': 4.982948303222656e-05},\n",
    " 'torch.utils._python_dispatch._disable_current_modes': {'count': 1,\n",
    "                                                         'total_time': 2.86102294921875e-06},\n",
    " 'torch.utils._python_dispatch._len_torch_dispatch_stack': {'count': 1,\n",
    "                                                            'total_time': 9.5367431640625e-07}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
