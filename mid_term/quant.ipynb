{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim     # for constructing optimizer\n",
    "import torchvision.models as models\n",
    "from module import *\n",
    "from function import *\n",
    "\n",
    "# 1. preparing the dataset\n",
    "class GDdataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.data = pd.read_csv(path)\n",
    "        SFR = torch.tensor(self.data.iloc[:, 2:46].values)\n",
    "        blocks = [SFR[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] # 将36列中的每4列合并成一个2*2矩阵，得到9个块\n",
    "        \n",
    "        self.value = torch.cat([torch.cat(blocks[i:i+3], dim=2) for i in range(0, 9, 3)], dim=1) # 将9个块按3*3的方式拼成一个大矩阵\n",
    "        self.value = self.value.unsqueeze(1).to(torch.float32)\n",
    "        \n",
    "        self.target = torch.tensor([1.0 if x == 'OK' else 0.0 for x in self.data.iloc[:, 48].values])\n",
    "        self.target = self.target.unsqueeze(1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.value[index], self.target[index]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import *\n",
    "# 2. define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(num_features=16)\n",
    "        self.fc1 = nn.Linear(in_features=16*3*3, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc4 = nn.Linear(in_features=32, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 1, 1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        # x = F.dropout(x, p=0.5)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def quantize(self, num_bits=8):\n",
    "        self.qconv = QConvBNReLU(self.conv, self.bn, qi=True, qo=True, num_bits=num_bits)\n",
    "        self.qmaxpool2d = QMaxPooling2d(kernel_size=1)\n",
    "        self.qfc1 = QLinear(self.fc1, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc2 = QLinear(self.fc2, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc3 = QLinear(self.fc3, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qfc4 = QLinear(self.fc4, qi=False, qo=True, num_bits=num_bits)\n",
    "        self.qsigmoid = QSigmoid(qi=False, qo=True, num_bits=num_bits)\n",
    "\n",
    "    def quantize_forward(self, x):\n",
    "        x = self.qconv(x)\n",
    "        x = self.qmaxpool2d(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.qfc1(x)\n",
    "        x = self.qfc2(x)\n",
    "        x = self.qfc3(x)\n",
    "        x = self.qfc4(x)\n",
    "        x = self.qsigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def freeze(self):\n",
    "        self.qconv.freeze()\n",
    "        self.qmaxpool2d.freeze(self.qconv.qo)\n",
    "        self.qfc1.freeze(qi=self.qconv.qo)\n",
    "        self.qfc2.freeze(qi=self.qfc1.qo)\n",
    "        self.qfc3.freeze(qi=self.qfc2.qo)\n",
    "        self.qfc4.freeze(qi=self.qfc3.qo)\n",
    "\n",
    "    def quantize_inference(self, x):\n",
    "        qx = self.qconv.qi.quantize_tensor(x)\n",
    "        qx = self.qconv.quantize_inference(qx)\n",
    "        qx = self.qmaxpool2d.quantize_inference(qx)\n",
    "        qx = qx.view(qx.shape[0], -1)\n",
    "        qx = self.qfc1.quantize_inference(qx)\n",
    "        qx = self.qfc2.quantize_inference(qx)\n",
    "        qx = self.qfc3.quantize_inference(qx)\n",
    "        qx = self.qfc4.quantize_inference(qx)\n",
    "        \n",
    "        out = self.qfc4.qo.dequantize_tensor(qx)\n",
    "        return out\n",
    "    \n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = GDdataset(\"./train_data.csv\")\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = GDdataset(\"./test_data.csv\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter   \n",
    "tb = SummaryWriter()\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "\n",
    "# 3. Construct Loss and Optimizer\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "# 4. define training cycle\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for batch_idx, (value, target) in enumerate(train_loader):\n",
    "        value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + update\n",
    "        output = model(value)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = (output > 0.5).float()\n",
    "        total_correct += (predicted == target).sum().item()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        progress = math.ceil(batch_idx / len(train_loader) * 50)\n",
    "        print(\"\\rTrain epoch %d: %d/%d, [%-51s] % d%%\" % (epoch, len(train_dataset), len(train_loader.dataset), '-' * progress + '>', progress * 2), end=\"\")\n",
    "        \n",
    "    # 输出每轮的loss\n",
    "    # print(\"\\n\\n[epoch %d] loss: %.3f train_accuracy: %d / %d=%.3f\" % (epoch+1, running_loss, total_correct, len(train_dataset), total_correct / len(train_dataset)))\n",
    "    \n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)              # scalar标量，即添加一个数字\n",
    "    tb.add_scalar(\"Number Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct / len(train_dataset), epoch)\n",
    "    \n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        correct = 0         # 分类正确个数\n",
    "        # total = 0           # 总数\n",
    "        test_loss = 0\n",
    "        for value, target in test_loader:\n",
    "            value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "            output = model(value)       # (batch_size, 1)\n",
    "            predicted = (output > 0.5).float()\n",
    "            # total += target.size(0)     # 加batch_size\n",
    "            correct += (predicted == target).sum().item()\n",
    "            test_loss += loss_function(output, target).item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        \n",
    "        print(\"\\nTest: average loss: {:.4f}, test_accuracy: {}/{} ({:.0f}%)\".format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        tb.add_scalar(\"Test_accuracy\", correct / len(test_loader.dataset), epoch)\n",
    "        \n",
    "    # print(\"Accuracy on test set: %.1f%%\" % (100 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2086/2194 (95%)\n",
      "Train epoch 1: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2097/2194 (96%)\n",
      "Train epoch 2: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2105/2194 (96%)\n",
      "Train epoch 3: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2119/2194 (97%)\n",
      "Train epoch 4: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2118/2194 (97%)\n",
      "Train epoch 5: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2123/2194 (97%)\n",
      "Train epoch 6: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0011, test_accuracy: 2114/2194 (96%)\n",
      "Train epoch 7: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0009, test_accuracy: 2125/2194 (97%)\n",
      "Train epoch 8: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0013, test_accuracy: 2090/2194 (95%)\n",
      "Train epoch 9: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0016, test_accuracy: 2052/2194 (94%)\n",
      "Train epoch 10: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0011, test_accuracy: 2100/2194 (96%)\n",
      "Train epoch 11: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2118/2194 (97%)\n",
      "Train epoch 12: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0013, test_accuracy: 2088/2194 (95%)\n",
      "Train epoch 13: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0011, test_accuracy: 2103/2194 (96%)\n",
      "Train epoch 14: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0009, test_accuracy: 2128/2194 (97%)\n",
      "Train epoch 15: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2119/2194 (97%)\n",
      "Train epoch 16: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0009, test_accuracy: 2127/2194 (97%)\n",
      "Train epoch 17: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0020, test_accuracy: 2033/2194 (93%)\n",
      "Train epoch 18: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0011, test_accuracy: 2103/2194 (96%)\n",
      "Train epoch 19: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2113/2194 (96%)\n",
      "Train epoch 20: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2118/2194 (97%)\n",
      "Train epoch 21: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0009, test_accuracy: 2124/2194 (97%)\n",
      "Train epoch 22: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0012, test_accuracy: 2088/2194 (95%)\n",
      "Train epoch 23: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0009, test_accuracy: 2132/2194 (97%)\n",
      "Train epoch 24: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2109/2194 (96%)\n",
      "Train epoch 25: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0008, test_accuracy: 2134/2194 (97%)\n",
      "Train epoch 26: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0009, test_accuracy: 2134/2194 (97%)\n",
      "Train epoch 27: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0009, test_accuracy: 2124/2194 (97%)\n",
      "Train epoch 28: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0010, test_accuracy: 2123/2194 (97%)\n",
      "Train epoch 29: 8773/8773, [-------------------------------------------------->]  100%\n",
      "Test: average loss: 0.0009, test_accuracy: 2124/2194 (97%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "torch.save(model.state_dict(), \"model1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model):   # 全精度推理\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0         # 分类正确个数\n",
    "        test_loss = 0\n",
    "        for value, target in test_loader:\n",
    "            value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "            output = model(value)       # (batch_size, 1)\n",
    "            predicted = (output > 0.5).float()\n",
    "            correct += (predicted == target).sum().item()\n",
    "            test_loss += loss_function(output, target).item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        \n",
    "    print(\"\\nTest: average loss: {:.4f}, test_accuracy: {}/{} ({:.0f}%)\".format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def qinference(model):  # 量化推理\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        correct = 0         # 分类正确个数\n",
    "        test_loss = 0\n",
    "        for value, target in test_loader:\n",
    "            value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "            output = model.quantize_inference(value)       # (batch_size, 1)\n",
    "            predicted = (output > 0.5).float()\n",
    "            correct += (predicted == target).sum().item()\n",
    "    print(\"\\ntest_accuracy: {}/{} ({:.0f}%)\".format(correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "            \n",
    "    \n",
    "def direct_quantize(model, test_loader):\n",
    "    for i, (value, target) in enumerate(test_loader, 1):\n",
    "        value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "        output = model.quantize_forward(value)\n",
    "        if i % 500 == 0:\n",
    "            break\n",
    "    print('direct quantization finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('model1.pt', map_location='cpu'))\n",
    "save_file = \"model1.pt\"\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: average loss: 0.0009, test_accuracy: 2124/2194 (97%)\n"
     ]
    }
   ],
   "source": [
    "inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct quantization finish\n",
      "\n",
      "test_accuracy: 1935/2194 (88%)\n"
     ]
    }
   ],
   "source": [
    "num_bits = 8\n",
    "model.quantize(num_bits=num_bits)\n",
    "direct_quantize(model, train_loader)\n",
    "# torch.save(model.state_dict(), save_file)\n",
    "model.freeze()\n",
    "qinference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling ...:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling ...:   1%|          | 1/100 [00:00<00:18,  5.25it/s]STAGE:2024-06-11 07:28:43 1978000:1978000 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-06-11 07:28:43 1978000:1978000 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-06-11 07:28:43 1978000:1978000 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "Profiling ...: 100%|██████████| 100/100 [00:00<00:00, 151.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.profiler\n",
    "from tqdm import tqdm\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('model1.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "profiler = torch.profiler.profile(\n",
    "    schedule=torch.profiler.schedule(wait=2, warmup=2, active=6, repeat=1),\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(dir_name='./performance/'),\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA\n",
    "    ],\n",
    "    with_stack=True,\n",
    ")\n",
    "profiler.start()\n",
    "with torch.no_grad():\n",
    "    # for value, target in test_loader:\n",
    "    #     value, target = value.to(device), target.to(device)    # 扔给GPU\n",
    "    #     output = model(value)       # (batch_size, 1)\n",
    "        # predicted = (output > 0.5).float()\n",
    "        # # total += target.size(0)     # 加batch_size\n",
    "        # correct += (predicted == target).sum().item()\n",
    "        # test_loss += loss_function(output, target).item()\n",
    "    for batch_idx in tqdm(range(100), desc='Profiling ...'):\n",
    "        value, _ = next(iter(train_loader))\n",
    "        model(value.to(device))\n",
    "        profiler.step()\n",
    "profiler.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct quantization finish\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('qmodel.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "num_bits = 4\n",
    "model.quantize(num_bits=num_bits)\n",
    "direct_quantize(model, train_loader)\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling ...:   0%|          | 0/100 [00:00<?, ?it/s]STAGE:2024-06-11 07:29:23 1978000:1978000 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-06-11 07:29:23 1978000:1978000 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-06-11 07:29:23 1978000:1978000 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "Profiling ...: 100%|██████████| 100/100 [00:00<00:00, 259.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.profiler\n",
    "from tqdm import tqdm\n",
    "profiler = torch.profiler.profile(\n",
    "    schedule=torch.profiler.schedule(wait=2, warmup=2, active=6, repeat=1),\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(dir_name='./performance/'),\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA\n",
    "    ],\n",
    "    with_stack=True,\n",
    ")\n",
    "profiler.start()\n",
    "with torch.no_grad():\n",
    "    for batch_idx in tqdm(range(100), desc='Profiling ...'):\n",
    "        value, _ = next(iter(train_loader))\n",
    "        model.quantize_inference(value.to(device))\n",
    "        profiler.step()\n",
    "profiler.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
