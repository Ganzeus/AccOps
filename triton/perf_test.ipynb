{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch-jixie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkernels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_atten_full_int8\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attention  \u001b[38;5;66;03m# 导入Triton的attention函数\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquant_pertoken\u001b[39m(X):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.utils.data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim     # for constructing optimizer\n",
    "from typing import Optional\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from kernels.flash_atten_full_int8 import attention  # 导入Triton的attention函数\n",
    "\n",
    "def quant_pertoken(X):\n",
    "    X_max, _ = torch.abs(X).max(dim=-1)\n",
    "    X_scale = X_max / 127\n",
    "    ret = torch.round(X / X_scale[:, :, :, None]).to(torch.int8)\n",
    "    return ret, X_scale\n",
    "\n",
    "def quant_pertensor(X):\n",
    "    X_max, _ = torch.abs(X).max(dim=-1)\n",
    "    X_max, _ = torch.max(X_max, dim=-1)\n",
    "    X_scale = X_max / 127\n",
    "    ret = torch.round(X / X_scale[:, :, None, None]).to(torch.int8)\n",
    "    return ret, X_scale\n",
    "\n",
    "class EnsureContiguousGrad(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.contiguous()\n",
    "\n",
    "class JXdataset(Dataset):\n",
    "    def __init__(self, path, scaler=None, is_training=True):\n",
    "        JX = pd.read_csv(path)\n",
    "        JX_data = JX.values\n",
    "        \n",
    "        features = JX_data[:, :-1]\n",
    "        targets = JX_data[:, -1]\n",
    "        \n",
    "        # NOTE: must normalize features or the model output will be nan\n",
    "        if is_training:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.features = self.scaler.fit_transform(features)\n",
    "        else:\n",
    "            self.features = scaler.transform(features)\n",
    "        \n",
    "        self.features = torch.tensor(self.features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.targets[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "# MultiheadAttention\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "        # regularization\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality\n",
    "        qkv = self.c_attn(x)\n",
    "        # 使用chunk更清晰地将张量分成三等份\n",
    "        q, k, v = qkv.chunk(3, dim=2)\n",
    "        \n",
    "        # 重塑为多头格式 [B, nh, T, hs]\n",
    "        head_size = self.n_embd // self.n_head\n",
    "        k = k.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
    "\n",
    "        # 计算注意力\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(head_size))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        y = att @ v\n",
    "        \n",
    "        # 重塑回原始形状\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        \n",
    "        # 输出投影\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=256, n_head=8, seq_len=256):\n",
    "        super().__init__()\n",
    "        assert hidden_dim % n_head == 0\n",
    "        self.config = type('Config', (), {\n",
    "            'n_embd': hidden_dim,\n",
    "            'n_head': n_head\n",
    "        })\n",
    "        \n",
    "        self.input_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.mha = MHA(self.config)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1).expand(-1, self.seq_len, -1)  # [B, seq_len, input_dim]\n",
    "        x = self.input_embedding(x)  # [B, seq_len, hidden_dim]\n",
    "        x = self.mha(x)              # [B, seq_len, hidden_dim]\n",
    "        x = self.output_layer(x)     # [B, seq_len, 1]\n",
    "        x = x[:, 0, :] # 取第一个时间步（等价于 cls token）\n",
    "        return x.squeeze(-1).squeeze(-1)\n",
    "\n",
    "class TritonMHA(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_head, seq_len=256):\n",
    "        super().__init__()\n",
    "        assert hidden_dim % n_head == 0\n",
    "        head_dim = hidden_dim // n_head\n",
    "        assert head_dim % 16 == 0 and head_dim >= 32\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_head = n_head\n",
    "        self.seq_len = seq_len\n",
    "        self.head_dim = head_dim\n",
    "\n",
    "        # 添加 qkv projection 和 output projection\n",
    "        self.c_attn = nn.Linear(hidden_dim, 3 * hidden_dim)\n",
    "        self.c_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # 1. QKV projection\n",
    "        qkv = self.c_attn(x)  # [B, T, 3 * hidden_dim]\n",
    "        q, k, v = qkv.chunk(3, dim=2)  # 分成三份\n",
    "\n",
    "        # 2. reshape: [B, n_head, T, head_dim]\n",
    "        q = q.view(batch_size, self.seq_len, self.n_head, self.head_dim).transpose(1, 2).contiguous()\n",
    "        k = k.view(batch_size, self.seq_len, self.n_head, self.head_dim).transpose(1, 2).contiguous()\n",
    "        v = v.view(batch_size, self.seq_len, self.n_head, self.head_dim).transpose(1, 2).contiguous()\n",
    "\n",
    "        # 3. Attention\n",
    "        sm_scale = 1.0 / math.sqrt(self.head_dim)\n",
    "        # 首先需要对q, k, v进行量化\n",
    "        q_int8, q_scale = quant_pertoken(q)  # 按token量化q\n",
    "        k_int8, k_scale = quant_pertoken(k)  # 按token量化k\n",
    "        v_int8, v_scale = quant_pertensor(v) # 按tensor量化v\n",
    "\n",
    "        # 然后调用attention_full_int8，传入所有所需参数\n",
    "        x = attention(q_int8, k_int8, v_int8, q_scale, k_scale, v_scale, True, sm_scale)\n",
    "        x = EnsureContiguousGrad.apply(x)\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, self.seq_len, self.hidden_dim)\n",
    "\n",
    "        # 4. Output projection\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "class NetWithTriton(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=256, n_head=8, seq_len=256):\n",
    "        super().__init__()\n",
    "        assert hidden_dim % n_head == 0\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.input_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.mha = TritonMHA(hidden_dim=hidden_dim, n_head=n_head, seq_len=seq_len)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1).expand(-1, self.seq_len, -1)  # [B, seq_len, input_dim]\n",
    "        x = self.input_embedding(x)                      # [B, seq_len, hidden_dim]\n",
    "        x = self.mha(x)                                  # [B, seq_len, hidden_dim]\n",
    "        x = self.output_layer(x)                         # [B, seq_len, 1]\n",
    "        x = x[:, 0, :]                                   # 取第一个时间步\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "def convert_pytorch_to_triton_model(pytorch_model):\n",
    "    \"\"\"\n",
    "    Converts PyTorch MHA-based model to Triton version, including qkv and proj weights\n",
    "    \"\"\"\n",
    "    triton_model = NetWithTriton(\n",
    "        input_dim=pytorch_model.input_embedding.in_features,\n",
    "        hidden_dim=pytorch_model.input_embedding.out_features,\n",
    "        n_head=pytorch_model.mha.n_head,\n",
    "        seq_len=256  # 确保与 Triton 要求一致\n",
    "    )\n",
    "\n",
    "    # 1. 拷贝输入嵌入层\n",
    "    triton_model.input_embedding.load_state_dict(pytorch_model.input_embedding.state_dict())\n",
    "\n",
    "    # 2. 拷贝 MHA 的 qkv 和 proj 层\n",
    "    triton_model.mha.c_attn.load_state_dict(pytorch_model.mha.c_attn.state_dict())\n",
    "    triton_model.mha.c_proj.load_state_dict(pytorch_model.mha.c_proj.state_dict())\n",
    "\n",
    "    # 3. 拷贝输出层\n",
    "    triton_model.output_layer.load_state_dict(pytorch_model.output_layer.state_dict())\n",
    "\n",
    "    return triton_model\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sas-jixie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please navigate to the link below to retreive your authentication code:\n",
      "\u001b[0;1;30;43mhttps://vfl-022.engage.sas.com/SASLogon/oauth/authorize?client_id=SWAT&response_type=code\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import swat\n",
    "import getpass\n",
    "\n",
    "sas_server_name = 'vfl-022.engage.sas.com'\n",
    "port_number = '443'\n",
    "\n",
    "sas_server_auth = '/SASLogon/oauth/authorize?client_id=SWAT&response_type=code'\n",
    "print('Please navigate to the link below to retreive your authentication code:\\n'+ '\\x1b[0;1;30;43m' + 'https://'  + sas_server_name + sas_server_auth + '\\x1b[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authcode = getpass.getpass('Authorization Code: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAS('vfl-022.engage.sas.com', 443, protocol='https', name='py-session-1', session='5bd38292-ede8-6540-9cc0-6c20677549ed')\n"
     ]
    }
   ],
   "source": [
    "conn_string = 'https://' + sas_server_name + ':' + port_number + '/cas-shared-default-http'\n",
    "conn = swat.CAS(conn_string, authcode=authcode)\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/sassoftware/python-dlpy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the file jixie_train_data.csv available as table JIXIE_TRAIN_DATA in caslib CASUSER(22321320@zju.edu.cn).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import swat\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import dlpy\n",
    "from dlpy import Sequential\n",
    "from dlpy import *\n",
    "from dlpy.model import TextParms\n",
    "from dlpy.blocks import Bidirectional\n",
    "from dlpy.applications import TextClassification\n",
    "from dlpy.network import *\n",
    "from dlpy.utils import *\n",
    "from dlpy.applications import *\n",
    "from dlpy.model import *\n",
    "from dlpy.images import *\n",
    "from dlpy.layers import *\n",
    "\n",
    "\n",
    "conn.loadTable(path='jixie_train_data.csv', casout={'name': 'jixie_train_data', 'caslib': 'casuser'}, importOptions={'fileType': 'csv'})\n",
    "tb = conn.CASTable('jixie_train_data', caslib='casuser')\n",
    "tb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5400.0    86\n",
       "3600.0    85\n",
       "4050.0    85\n",
       "4500.0    85\n",
       "4950.0    85\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = tb.head()\n",
    "df = (tb.f3.value_counts())\n",
    "display(type(df), df)\n",
    "# df.plot(kind='bar', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据的列名: ['f1', 'f2', 'f3', 'f4', 'tg']\n",
      "输入变量: ['f1', 'f2', 'f3', 'f4']\n",
      "目标变量: tg\n",
      "NOTE: Input layer added.\n",
      "NOTE: Fully-connected layer added.\n",
      "NOTE: Multi-head attention layer added.\n",
      "NOTE: Fully-connected layer added.\n",
      "NOTE: Output layer added.\n",
      "NOTE: Model compiled successfully.\n",
      "NOTE: Model compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集结构\n",
    "print(\"训练数据的列名:\", tb.columns.tolist())\n",
    "\n",
    "# 定义输入和目标变量\n",
    "input_vars = tb.columns[:-1].tolist()\n",
    "target_var = tb.columns[-1]\n",
    "print(\"输入变量:\", input_vars)\n",
    "print(\"目标变量:\", target_var)\n",
    "\n",
    "\n",
    "model = Sequential(conn, model_table='MHA_Regression_Simple')\n",
    "\n",
    "model.add(InputLayer(n_channels=4, name='input_layer'))\n",
    "model.add(Dense(n=32, act='relu', name='dense2'))\n",
    "model.add(MultiHeadAttention(n=32, n_attn_heads=2, name='mha_layer'))\n",
    "model.add(Dense(n=16, act='relu', name='pre_output'))\n",
    "model.add(OutputLayer(n=1, act='IDENTITY', name='output_layer'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile()\n",
    "\n",
    "# 训练模型\n",
    "# model.fit(\n",
    "#     data=tb,\n",
    "#     inputs=input_vars,\n",
    "#     target=target_var,\n",
    "#     mini_batch_size=16,\n",
    "#     max_epochs=30,\n",
    "#     log_level=2,\n",
    "#     lr=0.05\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer\n",
      "dense2\n",
      "mha_layer\n",
      "pre_output\n",
      "output_layer\n"
     ]
    }
   ],
   "source": [
    "# 查看模型的所有层\n",
    "print(model.layers[0])\n",
    "print(model.layers[1])\n",
    "print(model.layers[2])\n",
    "print(model.layers[3])\n",
    "print(model.layers[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "import types\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import swat\n",
    "import dlpy\n",
    "from dlpy import Sequential\n",
    "from dlpy.model import *\n",
    "from dlpy.layers import *\n",
    "from dlpy.utils import *\n",
    "\n",
    "# 创建一个字典来存储调用次数\n",
    "call_count = {}\n",
    "\n",
    "def count_calls(func, module_name=None):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_count_calls(*args, **kwargs):\n",
    "        full_name = module_name + '.' + func.__name__\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        if full_name not in call_count:\n",
    "            call_count[full_name] = {\"count\": 0, \"total_time\": 0.0}\n",
    "        \n",
    "        call_count[full_name][\"count\"] += 1\n",
    "        call_count[full_name][\"total_time\"] += elapsed_time\n",
    "        \n",
    "        return result\n",
    "    wrapper_count_calls._is_decorated = True\n",
    "    return wrapper_count_calls\n",
    "\n",
    "def set_new_attr(module, attr_name, attr):\n",
    "    if not hasattr(attr, \"_is_decorated\"):\n",
    "        decorated_attr = count_calls(attr, module.__name__)\n",
    "        decorated_attr._is_decorated = True\n",
    "        setattr(module, attr_name, decorated_attr)\n",
    "\n",
    "# 递归封装所有的包\n",
    "def auto_decorate_module(module, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    module_name = module.__name__\n",
    "    if module_name in visited:\n",
    "        return\n",
    "    visited.add(module_name)\n",
    "    for attr_name in dir(module):\n",
    "        try:\n",
    "            attr = getattr(module, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "            elif isinstance(attr, types.ModuleType) and attr.__name__.startswith('dlpy'):\n",
    "                auto_decorate_module(attr, visited)\n",
    "            elif isinstance(attr, type):\n",
    "                auto_decorate_class(attr)\n",
    "            elif callable(attr):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "def auto_decorate_class(cls):\n",
    "    for attr_name in dir(cls):\n",
    "        try:\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "            elif attr_name in ['__add__', '__mul__', '__sub__', '__truediv__', '__matmul__', '__pow__', '__mod__']:\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "        except (AttributeError, TypeError):\n",
    "            continue\n",
    "\n",
    "# 自动装饰 dlpy 模块及其子模块\n",
    "auto_decorate_module(dlpy)\n",
    "# 装饰 Layer 类的 __call__ 方法\n",
    "Layer.__call__ = count_calls(Layer.__call__, 'Layer')\n",
    "\n",
    "# 装饰 MultiHeadAttention.__call__\n",
    "from dlpy.layers import MultiHeadAttention\n",
    "# 同样先清理标记\n",
    "if hasattr(MultiHeadAttention.__call__, \"_is_decorated\"):\n",
    "    del MultiHeadAttention.__call__._is_decorated\n",
    "MultiHeadAttention.__call__ = count_calls(MultiHeadAttention.__call__,\n",
    "                                          'MultiHeadAttention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CASTable.__deepcopy__': {'count': 2, 'total_time': 0.0005397796630859375},\n",
      " 'CASTable.__getattr__': {'count': 1, 'total_time': 0.006033182144165039},\n",
      " 'CASTable.__init__': {'count': 2, 'total_time': 0.00045299530029296875},\n",
      " 'CASTable.__setattr__': {'count': 32, 'total_time': 7.987022399902344e-05},\n",
      " 'CASTable._fetch': {'count': 1, 'total_time': 0.7064030170440674},\n",
      " 'CASTable._retrieve': {'count': 1, 'total_time': 0.7049293518066406},\n",
      " 'CASTable._sample': {'count': 1, 'total_time': 1.6689300537109375e-06},\n",
      " 'CASTable._use_casout_for_stat': {'count': 2,\n",
      "                                   'total_time': 7.05718994140625e-05},\n",
      " 'CASTable.copy': {'count': 1, 'total_time': 0.0003101825714111328},\n",
      " 'CASTable.get_action_params': {'count': 1,\n",
      "                                'total_time': 5.0067901611328125e-06},\n",
      " 'CASTable.get_connection': {'count': 3, 'total_time': 7.867813110351562e-06},\n",
      " 'CASTable.get_fetch_params': {'count': 2,\n",
      "                               'total_time': 3.0994415283203125e-06},\n",
      " 'CASTable.get_groupby_vars': {'count': 4, 'total_time': 7.987022399902344e-05},\n",
      " 'CASTable.get_inputs_param': {'count': 1,\n",
      "                               'total_time': 1.1920928955078125e-06},\n",
      " 'CASTable.has_groupby_vars': {'count': 4, 'total_time': 6.365776062011719e-05},\n",
      " 'CASTable.has_params': {'count': 4, 'total_time': 5.078315734863281e-05},\n",
      " 'CASTable.head': {'count': 1, 'total_time': 0.7076163291931152},\n",
      " 'CASTable.retrieve': {'count': 1, 'total_time': 0.7049169540405273},\n",
      " 'CASTable.set_connection': {'count': 2, 'total_time': 9.298324584960938e-06},\n",
      " 'CASTable.set_params': {'count': 2, 'total_time': 1.6450881958007812e-05},\n",
      " 'CASTable.slice': {'count': 1, 'total_time': 0.7075498104095459},\n",
      " 'CASTable.to_table_params': {'count': 1, 'total_time': 1.4066696166992188e-05},\n",
      " 'Dense.__call__': {'count': 256, 'total_time': 0.0031402111053466797},\n",
      " 'Dense._assert_inputs': {'count': 256, 'total_time': 0.0001537799835205078},\n",
      " 'InputLayer.__call__': {'count': 128, 'total_time': 0.002099752426147461},\n",
      " 'InputLayer.__init__': {'count': 128, 'total_time': 0.003741025924682617},\n",
      " 'InputLayer._assert_inputs': {'count': 128,\n",
      "                               'total_time': 0.00011301040649414062},\n",
      " 'Layer.__call__': {'count': 512, 'total_time': 0.006563425064086914},\n",
      " 'Layer.__init__': {'count': 128, 'total_time': 0.000301361083984375},\n",
      " 'Layer._assert_inputs': {'count': 256, 'total_time': 0.0001633167266845703},\n",
      " 'MultiHeadAttention.__call__': {'count': 128,\n",
      "                                 'total_time': 0.0019559860229492188},\n",
      " 'Node.__init__': {'count': 640, 'total_time': 0.0004200935363769531},\n",
      " 'Tensor.__init__': {'count': 896, 'total_time': 0.0006172657012939453},\n",
      " 'dlpy.layers._unpack_config': {'count': 128,\n",
      "                                'total_time': 0.0010447502136230469},\n",
      " 'dlpy.layers.get_color': {'count': 128, 'total_time': 0.0002593994140625}}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_len = 256\n",
    "for index, row in tb.head(batch_size).iterrows():\n",
    "    # 创建输入张量\n",
    "    input_data = row.values[:4]\n",
    "    input_seq = np.tile(input_data, (seq_len, 1))\n",
    "    input_tensor = Tensor(InputLayer(256, 4))\n",
    "    input_tensor.shape = (256, 4)\n",
    "    input_tensor._value = input_data\n",
    "\n",
    "    # 前向计算并记录时间\n",
    "    output1 = model.layers[0](input_tensor)\n",
    "    dense_output = model.layers[1](output1)\n",
    "    mha_output = model.layers[2](dense_output)\n",
    "    pre_output = model.layers[3](mha_output)\n",
    "    output = model.layers[4](pre_output)\n",
    "\n",
    "pprint.pprint(call_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch-guangdian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.utils.data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim     # for constructing optimizer\n",
    "from typing import Optional\n",
    "import time\n",
    "from kernels.quantize_gemm_int8 import *\n",
    "from kernels.conv2d import conv2d_triton\n",
    "\n",
    "class GDdataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.data = pd.read_csv(path)\n",
    "        SFR = torch.tensor(self.data.iloc[:, 2:46].values)\n",
    "        blocks = [SFR[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] # 将36列中的每4列合并成一个2*2矩阵，得到9个块\n",
    "        \n",
    "        self.value = torch.cat([torch.cat(blocks[i:i+3], dim=2) for i in range(0, 9, 3)], dim=1) # 将9个块按3*3的方式拼成一个大矩阵\n",
    "        self.value = self.value.unsqueeze(1).to(torch.float32)\n",
    "        \n",
    "        self.target = torch.tensor([1.0 if x == 'OK' else 0.0 for x in self.data.iloc[:, 48].values])\n",
    "        self.target = self.target.unsqueeze(1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.value[index], self.target[index]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         # 卷积层\n",
    "#         # input:(batch_size, 1, 6, 6), output:(batch_size, num_kernels, 3, 3)\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=4096, kernel_size=2, stride=2),\n",
    "#             nn.BatchNorm2d(num_features=4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=1),\n",
    "#         )\n",
    "        \n",
    "#         # 全连接层\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(in_features=4096*3*3, out_features=8192),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(in_features=8192, out_features=4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(in_features=4096, out_features=2048),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(in_features=2048, out_features=1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(in_features=1024, out_features=256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(in_features=256, out_features=1),\n",
    "#         )\n",
    "        \n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         # x = x.view(x.shape[0], -1)  # (batch_size, 4096*3*3)\n",
    "#         B = x.shape[0]\n",
    "#         Cin = x.shape[1] * x.shape[2] * x.shape[3]  # 计算出 Cin = 4096 * 3 * 3\n",
    "#         T = 1  # 设置 T = 1，因为不涉及序列长度，这里作为占位符\n",
    "#         x = x.view(B, T, Cin)\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(x.shape[0], -1)    # (batch_size, 1)\n",
    "#         x = self.sigmoid(x)     \n",
    "#         return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层\n",
    "        # input:(batch_size, 1, 6, 6), output:(batch_size, num_kernels, 3, 3)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=16*3*3, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = x.view(x.shape[0], -1)  # (batch_size, 4096*3*3)\n",
    "        B = x.shape[0]\n",
    "        Cin = x.shape[1] * x.shape[2] * x.shape[3]  # 计算出 Cin = 4096 * 3 * 3\n",
    "        T = 1  # 设置 T = 1，因为不涉及序列长度，这里作为占位符\n",
    "        x = x.view(B, T, Cin)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], -1)    # (batch_size, 1)\n",
    "        x = self.sigmoid(x)     \n",
    "        return x\n",
    "\n",
    "class TritonLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # 初始化权重 (out_features, in_features)\n",
    "        self.weight = nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        # 预计算量化权重\n",
    "        self.register_buffer('quantized_weight', None)\n",
    "        self.register_buffer('weight_scale', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.quantize_weight()  # 初始化时预量化权重\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # 标准的 PyTorch 初始化方法\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def quantize_weight(self):\n",
    "        # 转置权重以匹配 matmul 需求：从 (out_features, in_features) 到 (in_features, out_features)\n",
    "        weight_t = self.weight.t().contiguous()\n",
    "        # 按列量化（相当于原始权重的行）\n",
    "        quantized_weight, weight_scale = quantize_int8(weight_t, axis=0)\n",
    "        self.quantized_weight = quantized_weight\n",
    "        self.weight_scale = weight_scale\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # 如果处于训练模式或权重尚未量化，则量化权重\n",
    "        if self.training or self.quantized_weight is None:\n",
    "            self.quantize_weight()\n",
    "        \n",
    "        # 处理输入\n",
    "        original_shape = input.shape\n",
    "        if input.dim() > 2:\n",
    "            # 将高维输入重塑为 2D\n",
    "            input = input.reshape(-1, input.size(-1))\n",
    "        \n",
    "        # 量化输入\n",
    "        quantized_input, input_scale = quantize_int8_perrow(input)\n",
    "        \n",
    "        # 执行量化矩阵乘法\n",
    "        output = matmul_int8(quantized_input, input_scale, \n",
    "                           self.quantized_weight, self.weight_scale)\n",
    "        \n",
    "        # 添加偏置（如果存在）\n",
    "        if self.bias is not None:\n",
    "            output = output + self.bias\n",
    "        \n",
    "        # 恢复原始维度（如果需要）\n",
    "        if len(original_shape) > 2:\n",
    "            output_shape = original_shape[:-1] + (self.out_features,)\n",
    "            output = output.reshape(output_shape)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class Conv2dTriton(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True, device=None, dtype=None):\n",
    "        super(Conv2dTriton, self).__init__()\n",
    "        \n",
    "        # Handle kernel_size as int or tuple\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        \n",
    "        # Currently, the Triton implementation only supports stride = kernel_size\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        \n",
    "        assert stride == kernel_size, \"The Triton implementation only supports stride == kernel_size\"\n",
    "        assert padding == 0, \"The Triton implementation doesn't support padding\"\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        self.weight = nn.Parameter(torch.empty((out_channels, in_channels, kernel_size[0], kernel_size[1])))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        # Standard initialization as in PyTorch\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ensure input dimensions are divisible by kernel dimensions\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        assert height % self.kernel_size[0] == 0 and width % self.kernel_size[1] == 0, \\\n",
    "            f\"Input height ({height}) and width ({width}) should be divisible by kernel dimensions ({self.kernel_size})\"\n",
    "        \n",
    "        # Use the Triton implementation\n",
    "        bias_tensor = self.bias if self.bias is not None else torch.zeros(self.out_channels, device=x.device, dtype=x.dtype)\n",
    "        output = conv2d_triton(x, self.weight, bias_tensor)\n",
    "        \n",
    "        # Ensure output has the same dtype as input\n",
    "        return output.to(x.dtype)\n",
    "\n",
    "\n",
    "# class NetWithTriton(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NetWithTriton, self).__init__()\n",
    "#         # Replace nn.Conv2d with Conv2dTriton\n",
    "#         self.conv = nn.Sequential(\n",
    "#             Conv2dTriton(in_channels=1, out_channels=4096, kernel_size=2, stride=2),\n",
    "#             nn.BatchNorm2d(num_features=4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=1),\n",
    "#         )\n",
    "        \n",
    "#         # Use TritonLinear for fully connected layers\n",
    "#         self.fc = nn.Sequential(\n",
    "#             TritonLinear(in_features=4096*3*3, out_features=8192),\n",
    "#             nn.ReLU(),\n",
    "#             TritonLinear(in_features=8192, out_features=4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             TritonLinear(in_features=4096, out_features=2048),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             TritonLinear(in_features=2048, out_features=1024),\n",
    "#             nn.ReLU(),\n",
    "#             TritonLinear(in_features=1024, out_features=256),\n",
    "#             nn.ReLU(),\n",
    "#             TritonLinear(in_features=256, out_features=1),\n",
    "#         )\n",
    "        \n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         B = x.shape[0]\n",
    "#         Cin = x.shape[1] * x.shape[2] * x.shape[3]  # Calculate Cin = 4096 * 3 * 3\n",
    "#         T = 1  # Set T = 1 as placeholder\n",
    "#         x = x.view(B, T, Cin)\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(x.shape[0], -1)  \n",
    "#         x = self.sigmoid(x)     \n",
    "#         return x\n",
    "\n",
    "class NetWithTriton(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetWithTriton, self).__init__()\n",
    "        # Replace nn.Conv2d with Conv2dTriton\n",
    "        self.conv = nn.Sequential(\n",
    "            Conv2dTriton(in_channels=1, out_channels=16, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # Use TritonLinear for fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            TritonLinear(in_features=16*3*3, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            TritonLinear(in_features=256, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            TritonLinear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(p=0.5),\n",
    "            TritonLinear(in_features=32, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        B = x.shape[0]\n",
    "        Cin = x.shape[1] * x.shape[2] * x.shape[3]  # Calculate Cin = 4096 * 3 * 3\n",
    "        T = 1  # Set T = 1 as placeholder\n",
    "        x = x.view(B, T, Cin)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], -1)  \n",
    "        x = self.sigmoid(x)     \n",
    "        return x\n",
    "\n",
    "def convert_pytorch_to_triton_model(pytorch_model):\n",
    "    \"\"\"\n",
    "    Convert standard PyTorch model to a model using TritonLinear and Conv2dTriton\n",
    "    \"\"\"\n",
    "    triton_model = NetWithTriton()\n",
    "    \n",
    "    # Copy Conv2d weights to Conv2dTriton\n",
    "    pytorch_conv = pytorch_model.conv[0]  # Get the Conv2d layer\n",
    "    triton_conv = triton_model.conv[0]    # Get the Conv2dTriton layer\n",
    "    \n",
    "    # Copy weights and bias\n",
    "    print(f\"Copying Conv weights: PyTorch {pytorch_conv.weight.shape} -> Triton {triton_conv.weight.shape}\")\n",
    "    triton_conv.weight.data.copy_(pytorch_conv.weight.data)\n",
    "    if hasattr(pytorch_conv, 'bias') and pytorch_conv.bias is not None:\n",
    "        triton_conv.bias.data.copy_(pytorch_conv.bias.data)\n",
    "    \n",
    "    # Copy other layers in the conv sequential (BatchNorm, etc.)\n",
    "    for i in range(1, len(pytorch_model.conv)):\n",
    "        print(f\"Copying layer: {type(pytorch_model.conv[i]).__name__}\")\n",
    "        triton_model.conv[i].load_state_dict(pytorch_model.conv[i].state_dict())\n",
    "    \n",
    "    # Copy linear layer weights to TritonLinear\n",
    "    pytorch_linears = [m for m in pytorch_model.fc if isinstance(m, nn.Linear)]\n",
    "    triton_linears = [m for m in triton_model.fc if isinstance(m, TritonLinear)]\n",
    "    \n",
    "    assert len(pytorch_linears) == len(triton_linears), \\\n",
    "        f\"Number of Linear layers doesn't match: PyTorch {len(pytorch_linears)} vs Triton {len(triton_linears)}\"\n",
    "    \n",
    "    for i, (pytorch_linear, triton_linear) in enumerate(zip(pytorch_linears, triton_linears)):\n",
    "        print(f\"Copying Linear {i+1} weights: PyTorch {pytorch_linear.weight.shape} -> Triton {triton_linear.weight.shape}\")\n",
    "        triton_linear.weight.data.copy_(pytorch_linear.weight.data)\n",
    "        if pytorch_linear.bias is not None:\n",
    "            triton_linear.bias.data.copy_(pytorch_linear.bias.data)\n",
    "        \n",
    "        # Update quantized weights\n",
    "        triton_linear.quantize_weight()\n",
    "    \n",
    "    return triton_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from call_count import call_count, monitor, reset_counters, print_statistics\n",
    "import time\n",
    "import types\n",
    "\n",
    "def run_inference(batch_sizes=[64, 128, 256, 512], num_batches=5):\n",
    "    \"\"\"\n",
    "    Run inference on Triton models and measure operator-level performance\n",
    "    \"\"\"\n",
    "    print(\"Starting inference test with real dataset...\")\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.set_device(device)  # Set default device\n",
    "    torch.cuda.empty_cache()  # Clear unused GPU memory\n",
    "    \n",
    "    # Try to load pre-trained model\n",
    "    try:\n",
    "        model_state_dict = torch.load(\"model.pt\")\n",
    "        print(\"Successfully loaded pre-trained model weights\")\n",
    "        pytorch_model = Net()\n",
    "        pytorch_model.load_state_dict(model_state_dict)\n",
    "    except:\n",
    "        print(\"Could not load pre-trained model, using default weights\")\n",
    "        pytorch_model = Net()\n",
    "    # pytorch_model = Net()\n",
    "    \n",
    "    # Convert model to use Triton implementations\n",
    "    pytorch_model = pytorch_model.to(device).half()\n",
    "    triton_model = convert_pytorch_to_triton_model(pytorch_model)\n",
    "    triton_model = triton_model.to(device).half()\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    triton_model.eval()\n",
    "    \n",
    "    # Add profiling for custom operators\n",
    "    def profile_method(instance, method_name, display_name):\n",
    "        \"\"\"Profile a method call and record time in call_count.\"\"\"\n",
    "        original_method = getattr(instance, method_name)\n",
    "        \n",
    "        def profiled_method(*args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            result = original_method(*args, **kwargs)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            \n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            if display_name not in call_count:\n",
    "                call_count[display_name] = {\"count\": 0, \"total_time\": 0.0}\n",
    "            \n",
    "            call_count[display_name][\"count\"] += 1\n",
    "            call_count[display_name][\"total_time\"] += elapsed_time\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        setattr(instance, method_name, profiled_method)\n",
    "        return original_method\n",
    "    \n",
    "    # Store original methods to restore later\n",
    "    originals = []\n",
    "    \n",
    "    # Profile the conv and fc sequential containers\n",
    "    originals.append((triton_model.conv, \"forward\", \n",
    "                    profile_method(triton_model.conv, \"forward\", \"triton_model.conv\")))\n",
    "    originals.append((triton_model.fc, \"forward\", \n",
    "                    profile_method(triton_model.fc, \"forward\", \"triton_model.fc\")))\n",
    "    \n",
    "    # Profile specific Conv2dTriton layers\n",
    "    for i, layer in enumerate(triton_model.conv):\n",
    "        if isinstance(layer, Conv2dTriton):\n",
    "            originals.append((layer, \"forward\", \n",
    "                            profile_method(layer, \"forward\", f\"Conv2dTriton[{i}]\")))\n",
    "    \n",
    "    # Profile specific TritonLinear layers\n",
    "    for i, layer in enumerate(triton_model.fc):\n",
    "        if isinstance(layer, TritonLinear):\n",
    "            originals.append((layer, \"forward\", \n",
    "                            profile_method(layer, \"forward\", f\"TritonLinear[{i}]\")))\n",
    "    \n",
    "    # Create the dataset once (we'll reuse it for different batch sizes)\n",
    "    try:\n",
    "        train_dataset = GDdataset(\"./train_data.csv\")\n",
    "        print(f\"Successfully loaded dataset with {len(train_dataset)} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Test for different batch sizes\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\n==== Batch Size: {batch_size} ====\")\n",
    "        \n",
    "        # Store batches for testing - manually shuffle the dataset indices\n",
    "        indices = torch.randperm(len(train_dataset), device='cpu').tolist()\n",
    "        test_batches = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        for i in range(0, min(len(indices), batch_size * num_batches), batch_size):\n",
    "            if batch_count >= num_batches:\n",
    "                break\n",
    "                \n",
    "            # Get a batch of indices\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            if len(batch_indices) < batch_size:\n",
    "                # Skip incomplete batches\n",
    "                continue\n",
    "                \n",
    "            # Collect inputs and targets for this batch\n",
    "            batch_inputs = []\n",
    "            batch_targets = []\n",
    "            for idx in batch_indices:\n",
    "                inp, tgt = train_dataset[idx]\n",
    "                batch_inputs.append(inp)\n",
    "                batch_targets.append(tgt)\n",
    "            \n",
    "            # Stack the tensors into a batch\n",
    "            inputs = torch.stack(batch_inputs).to(device).half()\n",
    "            targets = torch.stack(batch_targets).to(device).half()\n",
    "            \n",
    "            test_batches.append((inputs, targets))\n",
    "            batch_count += 1\n",
    "        \n",
    "        # Ensure we have enough batches\n",
    "        if len(test_batches) < num_batches:\n",
    "            print(f\"Warning: Could only extract {len(test_batches)} batches instead of {num_batches}\")\n",
    "            num_actual_batches = len(test_batches)\n",
    "        else:\n",
    "            num_actual_batches = num_batches\n",
    "        \n",
    "        # Verify data shape\n",
    "        print(f\"Input shape: {test_batches[0][0].shape}\")\n",
    "        \n",
    "        # Warmup\n",
    "        for i in range(min(10, len(test_batches))):\n",
    "            inputs, _ = test_batches[i % len(test_batches)]\n",
    "            with torch.no_grad():\n",
    "                _ = triton_model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Reset counters before measurement\n",
    "        reset_counters()\n",
    "        \n",
    "        # Triton model inference with operator-level profiling\n",
    "        with monitor():\n",
    "            for i in range(num_actual_batches):\n",
    "                inputs, targets = test_batches[i]\n",
    "                with torch.no_grad():\n",
    "                    triton_output = triton_model(inputs)\n",
    "                torch.cuda.synchronize()\n",
    "        \n",
    "        # Print operator-level statistics\n",
    "        print(\"\\nOperator-level performance statistics\")\n",
    "        print_statistics()\n",
    "        \n",
    "        # Print sample outputs for the last batch\n",
    "        batch_to_print = min(batch_size, triton_output.size(0))\n",
    "        print(f\"\\nSample output (first {min(5, batch_to_print)} from last batch):\")\n",
    "        for i in range(min(5, batch_to_print)):\n",
    "            print(f\"  Sample {i}: Output={triton_output[i].item():.4f}\")\n",
    "    \n",
    "    # Restore original methods\n",
    "    for instance, method_name, original in originals:\n",
    "        setattr(instance, method_name, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference test with real dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2519564/2227982509.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"model.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load pre-trained model, using default weights\n",
      "Copying Conv weights: PyTorch torch.Size([16, 1, 2, 2]) -> Triton torch.Size([16, 1, 2, 2])\n",
      "Copying layer: BatchNorm2d\n",
      "Copying layer: ReLU\n",
      "Copying layer: MaxPool2d\n",
      "Copying Linear 1 weights: PyTorch torch.Size([256, 144]) -> Triton torch.Size([256, 144])\n",
      "Copying Linear 2 weights: PyTorch torch.Size([64, 256]) -> Triton torch.Size([64, 256])\n",
      "Copying Linear 3 weights: PyTorch torch.Size([32, 64]) -> Triton torch.Size([32, 64])\n",
      "Copying Linear 4 weights: PyTorch torch.Size([1, 32]) -> Triton torch.Size([1, 32])\n",
      "Successfully loaded dataset with 8773 samples\n",
      "\n",
      "==== Batch Size: 128 ====\n",
      "Input shape: torch.Size([128, 1, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaozhe/workspace/suanzi/triton/call_count.py:157: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  attr = getattr(cls, attr_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Operator-level performance statistics\n",
      "Function Name                                      Count      Total Time (s)  Avg Time (s)   \n",
      "------------------------------------------------------------------------------------------\n",
      "OpOverloadPacket.__str__                           1928       0.001986        0.000001       \n",
      "torch._C._get_operation_overload                   964        0.005771        0.000006       \n",
      "OpOverloadPacket.__getattr__                       964        0.000962        0.000001       \n",
      "Module.__getattr__                                 130        0.000096        0.000001       \n",
      "Mapping.get                                        130        0.000253        0.000002       \n",
      "torch.cuda._cuda_isInBadFork                       125        0.000031        0.000000       \n",
      "torch.cuda.is_initialized                          125        0.000167        0.000001       \n",
      "torch.cuda._lazy_init                              125        0.000279        0.000002       \n",
      "torch._C._cuda_getDevice                           85         0.000060        0.000001       \n",
      "torch._C._get_tracing_state                        80         0.000071        0.000001       \n",
      "torch.jit.is_scripting                             80         0.000015        0.000000       \n",
      "Module._call_impl                                  65         0.087826        0.001351       \n",
      "Module._wrapped_call_impl                          65         0.087919        0.001353       \n",
      "lazy_property.__get__                              64         0.000072        0.000001       \n",
      "torch.empty                                        45         0.000293        0.000007       \n",
      "torch.cuda._is_compiled                            40         0.000019        0.000000       \n",
      "torch.cuda._nvml_based_avail                       40         0.000147        0.000004       \n",
      "torch._C._cuda_getDeviceCount                      40         0.000016        0.000000       \n",
      "torch.cuda.is_available                            40         0.000284        0.000007       \n",
      "torch._utils._get_available_device_type            40         0.000327        0.000008       \n",
      "torch.cuda.current_device                          40         0.000192        0.000005       \n",
      "torch._utils._get_device_attr                      40         0.000611        0.000015       \n",
      "torch._utils._get_current_device_index             40         0.000657        0.000016       \n",
      "torch.cuda._utils._get_device_index                40         0.000745        0.000019       \n",
      "torch.cuda._get_device_index                       40         0.000872        0.000022       \n",
      "device.__init__                                    40         0.000926        0.000023       \n",
      "torch.cuda._cuda_exchangeDevice                    40         0.000021        0.000001       \n",
      "device.__enter__                                   40         0.000073        0.000002       \n",
      "torch._C._cuda_synchronize                         40         0.025621        0.000641       \n",
      "torch.cuda._cuda_maybeExchangeDevice               40         0.000021        0.000001       \n",
      "device.__exit__                                    40         0.000069        0.000002       \n",
      "torch.cuda.synchronize                             40         0.026989        0.000675       \n",
      "_ClassPropertyDescriptor.__get__                   36         0.000085        0.000002       \n",
      "torch.nn.functional._has_torch_function_unary      30         0.000008        0.000000       \n",
      "BatchNorm2d.__getattr__                            25         0.000014        0.000001       \n",
      "torch.relu                                         20         0.000287        0.000014       \n",
      "torch.nn.functional.relu                           20         0.000350        0.000017       \n",
      "ReLU.forward                                       20         0.000381        0.000019       \n",
      "torch.zeros                                        20         0.000333        0.000017       \n",
      "Tensor.__add__                                     20         0.000331        0.000017       \n",
      "_GenericAlias.__getattr__                          18         0.000013        0.000001       \n",
      "torch.is_grad_enabled                              15         0.000007        0.000000       \n",
      "ContextProp.__get__                                12         0.000013        0.000001       \n",
      "torch._C._set_grad_enabled                         10         0.000015        0.000001       \n",
      "set_grad_enabled.__init__                          10         0.000044        0.000004       \n",
      "Sequential.__iter__                                10         0.000008        0.000001       \n",
      "_lazy_property_and_property.__init__               8          0.000008        0.000001       \n",
      "SymIntMemoDescriptor._memo                         8          0.000007        0.000001       \n",
      "_NoParamDecoratorContextManager.__new__            5          0.000008        0.000002       \n",
      "torch._jit_internal.is_scripting                   5          0.000001        0.000000       \n",
      "no_grad.__init__                                   5          0.000015        0.000003       \n",
      "no_grad.__enter__                                  5          0.000041        0.000008       \n",
      "Conv2dTriton[0]                                    5          0.005795        0.001159       \n",
      "BatchNorm2d._check_input_dim                       5          0.000003        0.000001       \n",
      "torch.nn.functional._has_torch_function_variadic   5          0.000001        0.000000       \n",
      "torch.batch_norm                                   5          0.000313        0.000063       \n",
      "torch.nn.functional.batch_norm                     5          0.000350        0.000070       \n",
      "BatchNorm2d.forward                                5          0.000419        0.000084       \n",
      "BatchNorm2d._call_impl                             5          0.000443        0.000089       \n",
      "BatchNorm2d._wrapped_call_impl                     5          0.000451        0.000090       \n",
      "torch.max_pool2d                                   5          0.000089        0.000018       \n",
      "torch.nn.functional.max_pool2d                     5          0.000111        0.000022       \n",
      "MaxPool2d.forward                                  5          0.000123        0.000025       \n",
      "MaxPool2d._call_impl                               5          0.000142        0.000028       \n",
      "MaxPool2d._wrapped_call_impl                       5          0.000149        0.000030       \n",
      "triton_model.conv                                  5          0.010683        0.002137       \n",
      "TritonLinear[0]                                    5          0.006316        0.001263       \n",
      "TritonLinear[2]                                    5          0.003789        0.000758       \n",
      "torch.nn.functional.dropout                        5          0.000041        0.000008       \n",
      "Dropout.forward                                    5          0.000050        0.000010       \n",
      "Dropout._call_impl                                 5          0.000069        0.000014       \n",
      "Dropout._wrapped_call_impl                         5          0.000077        0.000015       \n",
      "TritonLinear[5]                                    5          0.004808        0.000962       \n",
      "TritonLinear[7]                                    5          0.004410        0.000882       \n",
      "triton_model.fc                                    5          0.020141        0.004028       \n",
      "torch.sigmoid                                      5          0.000076        0.000015       \n",
      "Sigmoid.forward                                    5          0.000085        0.000017       \n",
      "no_grad.__exit__                                   5          0.000029        0.000006       \n",
      "torch._C._get_qengine                              1          0.000025        0.000025       \n",
      "torch._C._supported_qengines                       1          0.000005        0.000005       \n",
      "\n",
      "Sample output (first 5 from last batch):\n",
      "  Sample 0: Output=0.4814\n",
      "  Sample 1: Output=0.4817\n",
      "  Sample 2: Output=0.4817\n",
      "  Sample 3: Output=0.4817\n",
      "  Sample 4: Output=0.4805\n"
     ]
    }
   ],
   "source": [
    "run_inference(batch_sizes=[128], num_batches=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sas-guangdian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please navigate to the link below to retreive your authentication code:\n",
      "\u001b[0;1;30;43mhttps://vfl-022.engage.sas.com/SASLogon/oauth/authorize?client_id=SWAT&response_type=code\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import swat\n",
    "import getpass\n",
    "\n",
    "sas_server_name = 'vfl-022.engage.sas.com'\n",
    "port_number = '443'\n",
    "\n",
    "sas_server_auth = '/SASLogon/oauth/authorize?client_id=SWAT&response_type=code'\n",
    "print('Please navigate to the link below to retreive your authentication code:\\n'+ '\\x1b[0;1;30;43m' + 'https://'  + sas_server_name + sas_server_auth + '\\x1b[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authcode = getpass.getpass('Authorization Code: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAS('vfl-022.engage.sas.com', 443, protocol='https', name='py-session-1', session='2f846508-19f3-824d-9a7a-d1010aae8170')\n"
     ]
    }
   ],
   "source": [
    "conn_string = 'https://' + sas_server_name + ':' + port_number + '/cas-shared-default-http'\n",
    "conn = swat.CAS(conn_string, authcode=authcode)\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the file guangdian_train_data.csv available as table GUANGDIAN_TRAIN_DATA in caslib CASUSER(22321320@zju.edu.cn).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8773, 52)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import swat\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import dlpy\n",
    "import functools\n",
    "import time\n",
    "import types\n",
    "import pprint\n",
    "from dlpy import Sequential\n",
    "from dlpy import *\n",
    "from dlpy.model import TextParms\n",
    "from dlpy.blocks import Bidirectional\n",
    "from dlpy.applications import TextClassification\n",
    "from dlpy.network import *\n",
    "from dlpy.utils import *\n",
    "from dlpy.applications import *\n",
    "from dlpy.model import *\n",
    "from dlpy.images import *\n",
    "from dlpy.layers import *\n",
    "\n",
    "\n",
    "conn.loadTable(path='guangdian_train_data.csv', casout={'name': 'guangdian_train_data', 'caslib': 'casuser'}, importOptions={'fileType': 'csv'})\n",
    "tb = conn.CASTable('guangdian_train_data', caslib='casuser')\n",
    "tb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the uploaded file available as table TRAIN_DATA in caslib CASUSER(22321320@zju.edu.cn).\n",
      "NOTE: The table TRAIN_DATA has been created in caslib CASUSER(22321320@zju.edu.cn) from binary data uploaded to Cloud Analytic Services.\n"
     ]
    }
   ],
   "source": [
    "SFR = tb.iloc[:, 2:46].values\n",
    "blocks = [SFR[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] # 将36列中的每4列合并成一个2*2矩阵，得到9个块\n",
    "x_train = np.concatenate([np.concatenate(blocks[i:i+3], axis=2) for i in range(0, 9, 3)], axis=1) # 将9个块按3*3的方式拼成一个大矩阵\n",
    "# 修改train_data\n",
    "# 将 numpy 数组转换为 pandas DataFrame\n",
    "X_train_flat = x_train.reshape(8773, -1)  # 展平图像数据\n",
    "df_train = pd.DataFrame(X_train_flat)\n",
    "df_train['label'] = tb.SFR_Result\n",
    "df_train['label'] = df_train['label'].map({'OK': 1, 'NG': 0})\n",
    "train_data = conn.upload_frame(df_train, casout={'name':'train_data', 'replace':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head><title>504 Gateway Time-out</title></head>\n",
      "<body>\n",
      "<center><h1>504 Gateway Time-out</h1></center>\n",
      "<hr><center>Microsoft-Azure-Application-Gateway/v2</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "/home/gaozhe/anaconda3/envs/triton/lib/python3.10/site-packages/dlpy/network.py:1948: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if layer.type is not 'input':\n",
      "/home/gaozhe/anaconda3/envs/triton/lib/python3.10/site-packages/dlpy/network.py:1948: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if layer.type is not 'input':\n",
      "/home/gaozhe/anaconda3/envs/triton/lib/python3.10/site-packages/dlpy/network.py:1948: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if layer.type is not 'input':\n",
      "/home/gaozhe/anaconda3/envs/triton/lib/python3.10/site-packages/dlpy/network.py:1948: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if layer.type is not 'input':\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 模型定义和训练\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSimple_CNN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(InputLayer(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2d(n_filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, act\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/dlpy/sequential.py:49\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[0;34m(self, conn, layers, model_table)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn, layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSequential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/dlpy/network.py:79\u001b[0m, in \u001b[0;36mNetwork.__init__\u001b[0;34m(self, conn, inputs, outputs, model_table, model_weights)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf one of inputs and outputs option is enabled, both should be specified\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# works for Sequential() as well as objects that inherit the Model class\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, dlpy\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mModel):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# 1). Model(s, model_table, model_weights)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# 2). Model(s, inp, outputs, model_table, model_weights)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/dlpy/network.py:88\u001b[0m, in \u001b[0;36mNetwork._init_model\u001b[0;34m(self, conn, model_table, model_weights)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn, model_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadactionset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactionSet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeeplearn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_messagelevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconn \u001b[38;5;241m=\u001b[39m conn\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(_self_, actionset, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/swat/cas/actions.py:851\u001b[0m, in \u001b[0;36mCASAction.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    834\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m    Call the action\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    849\u001b[0m \n\u001b[1;32m    850\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 851\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmergedefined\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/swat/cas/connection.py:2102\u001b[0m, in \u001b[0;36mCAS.retrieve\u001b[0;34m(self, _name_, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresultfunc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2101\u001b[0m     \u001b[38;5;66;03m# Call the action and compile the results\u001b[39;00m\n\u001b[0;32m-> 2102\u001b[0m     signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_with_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma2n\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_name_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2103\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_results(getnext(\u001b[38;5;28mself\u001b[39m, datamsghandler\u001b[38;5;241m=\u001b[39mdatamsghandler),\n\u001b[1;32m   2104\u001b[0m                                 responsefunc\u001b[38;5;241m=\u001b[39mresponsefunc, resultfunc\u001b[38;5;241m=\u001b[39mresultfunc)\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SWATCASActionRetry:\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/swat/cas/connection.py:1538\u001b[0m, in \u001b[0;36mCAS._invoke_with_signature\u001b[0;34m(self, _name_, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m   1536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_param_args(signature\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m, {}), kwargs, action\u001b[38;5;241m=\u001b[39m_name_)\n\u001b[0;32m-> 1538\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_without_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_name_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signature\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/swat/cas/connection.py:1313\u001b[0m, in \u001b[0;36mCAS._invoke_without_signature\u001b[0;34m(self, _name_, **kwargs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;124;03mCall an action on the server\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \n\u001b[1;32m   1311\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sw_connection, rest\u001b[38;5;241m.\u001b[39mREST_CASConnection):\n\u001b[0;32m-> 1313\u001b[0m     errorcheck(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sw_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma2n\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_name_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1314\u001b[0m                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sw_connection)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     errorcheck(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sw_connection\u001b[38;5;241m.\u001b[39minvoke(a2n(_name_),\n\u001b[1;32m   1317\u001b[0m                                           py2cas(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soptions,\n\u001b[1;32m   1318\u001b[0m                                                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sw_error, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)),\n\u001b[1;32m   1319\u001b[0m                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sw_connection)\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/swat/cas/rest/connection.py:713\u001b[0m, in \u001b[0;36mREST_CASConnection.invoke\u001b[0;34m(self, action_name, kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     txt \u001b[38;5;241m=\u001b[39m a2u(res\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(res\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# 模型定义和训练\n",
    "model = Sequential(conn, model_table='Simple_CNN')\n",
    "model.add(InputLayer(1, 6, 6))\n",
    "model.add(Conv2d(n_filters=16, width=2, height=2, stride=2, act='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Pooling(1))\n",
    "model.add(Dense(16*3*3, act='relu'))\n",
    "model.add(Dense(256, act='relu'))\n",
    "model.add(Dense(64, act='relu'))\n",
    "model.add(Dense(32, act='relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(OutputLayer(act='sigmoid', n=1))\n",
    "\n",
    "# model = Sequential(conn, model_table='Simple_CNN')\n",
    "# model.add(InputLayer(1, 6, 6))\n",
    "# model.add(Conv2d(n_filters=4096, width=2, height=2, stride=2, act='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Pooling(1))\n",
    "# model.add(Dense(4096*3*3, act='relu'))\n",
    "# model.add(Dense(8192, act='relu'))\n",
    "# model.add(Dense(4096, act='relu'))\n",
    "# model.add(Dense(2048, act='relu'))\n",
    "# model.add(Dense(1024, act='relu'))\n",
    "# model.add(Dense(256, act='relu'))\n",
    "# model.add(Dense(1))\n",
    "# model.add(OutputLayer(act='sigmoid', n=1))\n",
    "\n",
    "input_vars = train_data.columns[:-1].tolist()  # 除去 'label' 列的所有列名\n",
    "target_var = 'label'\n",
    "model.fit(\n",
    "    data=train_data,\n",
    "    inputs=input_vars,\n",
    "    target=target_var,\n",
    "    mini_batch_size=128,\n",
    "    max_epochs=100,\n",
    "    lr = 0.1,\n",
    "    n_threads=1,\n",
    "    log_level=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个字典来存储调用次数\n",
    "call_count = {}\n",
    "\n",
    "def count_calls(func, module_name=None):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_count_calls(*args, **kwargs):\n",
    "        full_name = module_name + '.' + func.__name__\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        if full_name not in call_count:\n",
    "            call_count[full_name] = {\"count\": 0, \"total_time\": 0.0}\n",
    "        \n",
    "        call_count[full_name][\"count\"] += 1\n",
    "        call_count[full_name][\"total_time\"] += elapsed_time\n",
    "        \n",
    "        return result\n",
    "    wrapper_count_calls._is_decorated = True\n",
    "    return wrapper_count_calls\n",
    "\n",
    "def set_new_attr(module, attr_name, attr):\n",
    "    if not hasattr(attr, \"_is_decorated\"):\n",
    "        decorated_attr = count_calls(attr, module.__name__)\n",
    "        decorated_attr._is_decorated = True\n",
    "        setattr(module, attr_name, decorated_attr)\n",
    "\n",
    "# 递归封装所有的包\n",
    "def auto_decorate_module(module, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    module_name = module.__name__\n",
    "    if module_name in visited:\n",
    "        return\n",
    "    visited.add(module_name)\n",
    "    for attr_name in dir(module):\n",
    "        try:\n",
    "            attr = getattr(module, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "            elif isinstance(attr, types.ModuleType) and attr.__name__.startswith('dlpy'):\n",
    "                auto_decorate_module(attr, visited)\n",
    "            elif isinstance(attr, type):\n",
    "                auto_decorate_class(attr)\n",
    "            elif callable(attr):\n",
    "                set_new_attr(module, attr_name, attr)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "def auto_decorate_class(cls):\n",
    "    for attr_name in dir(cls):\n",
    "        try:\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "            elif attr_name in ['__add__', '__mul__', '__sub__', '__truediv__', '__matmul__', '__pow__', '__mod__']:\n",
    "                set_new_attr(cls, attr_name, attr)\n",
    "        except (AttributeError, TypeError):\n",
    "            continue\n",
    "\n",
    "# 自动装饰 dlpy 模块及其子模块\n",
    "auto_decorate_module(dlpy)\n",
    "# 装饰 Layer 类的 __call__ 方法\n",
    "Layer.__call__ = count_calls(Layer.__call__, 'Layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BN.__call__': {'count': 128, 'total_time': 0.0017046928405761719},\n",
      " 'BN._assert_inputs': {'count': 128, 'total_time': 7.414817810058594e-05},\n",
      " 'Conv2d.__call__': {'count': 128, 'total_time': 0.002118825912475586},\n",
      " 'Conv2d._assert_inputs': {'count': 128, 'total_time': 0.0001163482666015625},\n",
      " 'Dense.__call__': {'count': 640, 'total_time': 0.0071752071380615234},\n",
      " 'Dense._assert_inputs': {'count': 640, 'total_time': 0.00035572052001953125},\n",
      " 'InputLayer.__init__': {'count': 128, 'total_time': 0.0036852359771728516},\n",
      " 'Layer.__call__': {'count': 1536, 'total_time': 0.026607990264892578},\n",
      " 'Layer.__init__': {'count': 128, 'total_time': 0.0003139972686767578},\n",
      " 'Layer._assert_inputs': {'count': 256, 'total_time': 0.00020241737365722656},\n",
      " 'Node.__init__': {'count': 1152, 'total_time': 0.0007941722869873047},\n",
      " 'Tensor.__init__': {'count': 1408, 'total_time': 0.0009775161743164062},\n",
      " 'dlpy.layers._unpack_config': {'count': 128,\n",
      "                                'total_time': 0.0010874271392822266},\n",
      " 'dlpy.layers.get_color': {'count': 128, 'total_time': 0.0002605915069580078}}\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "# 遍历 train_data 中的batch行进行前向计算\n",
    "for index, row in df_train.head(batch_size).iterrows():\n",
    "    # 从 test_data 中获取当前行的前 36 个元素，并将其重塑为 6x6 矩阵\n",
    "    input_data = row.values[:36].reshape((1, 1, 6, 6))\n",
    "    \n",
    "    # 创建输入张量\n",
    "    input_tensor = Tensor(InputLayer(1, 6, 6))\n",
    "    input_tensor.shape = (1, 1, 6, 6)\n",
    "    input_tensor._value = input_data\n",
    "\n",
    "    # 前向计算并记录时间\n",
    "    conv_output = model.layers[1](input_tensor)\n",
    "    batch_norm_output = model.layers[2](conv_output)\n",
    "    pooling_output = model.layers[3](batch_norm_output)\n",
    "    dense_output1 = model.layers[4](pooling_output)\n",
    "    dense_output2 = model.layers[5](dense_output1)\n",
    "    dense_output3 = model.layers[6](dense_output2)\n",
    "    dense_output4 = model.layers[7](dense_output3)\n",
    "    dense_output5 = model.layers[8](dense_output4)\n",
    "    output = model.layers[9](dense_output5)\n",
    "\n",
    "pprint.pprint(call_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
