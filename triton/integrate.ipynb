{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.utils.data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim     # for constructing optimizer\n",
    "from typing import Optional\n",
    "import time\n",
    "from kernels.quantize_gemm_int8 import *\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层\n",
    "        # input:(batch_size, 1, 6, 6), output:(batch_size, num_kernels, 3, 3)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4096, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=4096*3*3, out_features=8192),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=8192, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = x.view(x.shape[0], -1)  # (batch_size, 4096*3*3)\n",
    "        B = x.shape[0]\n",
    "        Cin = x.shape[1] * x.shape[2] * x.shape[3]  # 计算出 Cin = 4096 * 3 * 3\n",
    "        T = 1  # 设置 T = 1，因为不涉及序列长度，这里作为占位符\n",
    "        x = x.view(B, T, Cin)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], -1)    # (batch_size, 1)\n",
    "        x = self.sigmoid(x)     \n",
    "        return x\n",
    "    \n",
    "class TritonLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # 初始化权重 (out_features, in_features)\n",
    "        self.weight = nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        # 预计算量化权重\n",
    "        self.register_buffer('quantized_weight', None)\n",
    "        self.register_buffer('weight_scale', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.quantize_weight()  # 初始化时预量化权重\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # 标准的 PyTorch 初始化方法\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def quantize_weight(self):\n",
    "        # 转置权重以匹配 matmul 需求：从 (out_features, in_features) 到 (in_features, out_features)\n",
    "        weight_t = self.weight.t().contiguous()\n",
    "        # 按列量化（相当于原始权重的行）\n",
    "        quantized_weight, weight_scale = quantize_int8(weight_t, axis=0)\n",
    "        self.quantized_weight = quantized_weight\n",
    "        self.weight_scale = weight_scale\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # 如果处于训练模式或权重尚未量化，则量化权重\n",
    "        if self.training or self.quantized_weight is None:\n",
    "            self.quantize_weight()\n",
    "        \n",
    "        # 处理输入\n",
    "        original_shape = input.shape\n",
    "        if input.dim() > 2:\n",
    "            # 将高维输入重塑为 2D\n",
    "            input = input.reshape(-1, input.size(-1))\n",
    "        \n",
    "        # 量化输入\n",
    "        quantized_input, input_scale = quantize_int8_perrow(input)\n",
    "        \n",
    "        # 执行量化矩阵乘法\n",
    "        output = matmul_int8(quantized_input, input_scale, \n",
    "                           self.quantized_weight, self.weight_scale)\n",
    "        \n",
    "        # 添加偏置（如果存在）\n",
    "        if self.bias is not None:\n",
    "            output = output + self.bias\n",
    "        \n",
    "        # 恢复原始维度（如果需要）\n",
    "        if len(original_shape) > 2:\n",
    "            output_shape = original_shape[:-1] + (self.out_features,)\n",
    "            output = output.reshape(output_shape)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "class NetWithTriton(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetWithTriton, self).__init__()\n",
    "        # 卷积层保持不变\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4096, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # 全连接层替换为TritonLinear\n",
    "        self.fc = nn.Sequential(\n",
    "            TritonLinear(in_features=4096*3*3, out_features=8192),\n",
    "            nn.ReLU(),\n",
    "            TritonLinear(in_features=8192, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            TritonLinear(in_features=4096, out_features=2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            TritonLinear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            TritonLinear(in_features=1024, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            TritonLinear(in_features=256, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        B = x.shape[0]\n",
    "        Cin = x.shape[1] * x.shape[2] * x.shape[3]  # 计算出 Cin = 4096 * 3 * 3\n",
    "        T = 1  # 设置 T = 1，因为不涉及序列长度，这里作为占位符\n",
    "        x = x.view(B, T, Cin)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], -1)    # (batch_size, 1)\n",
    "        x = self.sigmoid(x)     \n",
    "        return x\n",
    "    \n",
    "def convert_pytorch_to_triton_model(pytorch_model):\n",
    "    \"\"\"\n",
    "    将标准 PyTorch 模型转换为使用 TritonLinear 的模型\n",
    "    \"\"\"\n",
    "    triton_model = NetWithTriton()\n",
    "    \n",
    "    # 复制卷积层权重\n",
    "    triton_model.conv.load_state_dict(pytorch_model.conv.state_dict())\n",
    "    \n",
    "    # 直接按顺序匹配Linear层\n",
    "    pytorch_linears = [m for m in pytorch_model.fc if isinstance(m, nn.Linear)]\n",
    "    triton_linears = [m for m in triton_model.fc if isinstance(m, TritonLinear)]\n",
    "    \n",
    "    # 确保两者有相同数量的Linear层\n",
    "    assert len(pytorch_linears) == len(triton_linears), \"PyTorch和Triton模型的Linear层数量不匹配\"\n",
    "    \n",
    "    # 逐一复制权重\n",
    "    for pytorch_linear, triton_linear in zip(pytorch_linears, triton_linears):\n",
    "        # 打印出形状以便调试\n",
    "        print(f\"复制权重: PyTorch {pytorch_linear.weight.shape} -> Triton {triton_linear.weight.shape}\")\n",
    "        \n",
    "        # 确保形状匹配\n",
    "        assert pytorch_linear.weight.shape == triton_linear.weight.shape, \\\n",
    "            f\"权重形状不匹配: PyTorch {pytorch_linear.weight.shape} vs Triton {triton_linear.weight.shape}\"\n",
    "        \n",
    "        # 复制权重和偏置\n",
    "        triton_linear.weight.data.copy_(pytorch_linear.weight.data)\n",
    "        if pytorch_linear.bias is not None and triton_linear.bias is not None:\n",
    "            triton_linear.bias.data.copy_(pytorch_linear.bias.data)\n",
    "        \n",
    "        # 更新量化权重\n",
    "        triton_linear.quantize_weight()\n",
    "    \n",
    "    return triton_model\n",
    "\n",
    "def run_inference(batch_sizes=[64, 128, 256, 512], num_batches=5):\n",
    "    \"\"\"\n",
    "    运行多批次推理并比较 PyTorch 和 Triton 模型性能\n",
    "    \"\"\"\n",
    "    print(\"开始推理测试...\")\n",
    "    \n",
    "    # 定义设备\n",
    "    device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.set_device(device)  # 确保默认设备是device\n",
    "    torch.cuda.empty_cache()  # 清空未使用的 GPU 内存\n",
    "    \n",
    "    # 尝试加载预训练模型\n",
    "    try:\n",
    "        model_state_dict = torch.load(\"model.pt\")\n",
    "        print(\"成功加载预训练模型权重\")\n",
    "        pytorch_model = Net()\n",
    "        pytorch_model.load_state_dict(model_state_dict)\n",
    "    except:\n",
    "        print(\"无法加载预训练模型，使用默认初始化权重\")\n",
    "        pytorch_model = Net()\n",
    "    \n",
    "    # 将模型转为使用 Triton 实现的版本\n",
    "    pytorch_model = pytorch_model.to(device).half()\n",
    "    triton_model = convert_pytorch_to_triton_model(pytorch_model)\n",
    "    triton_model = triton_model.to(device).half()\n",
    "    \n",
    "    # 设置为评估模式\n",
    "    pytorch_model.eval()\n",
    "    triton_model.eval()\n",
    "    \n",
    "    # 针对不同批次大小进行测试\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\n==== 批次大小: {batch_size} ====\")\n",
    "        \n",
    "        # 准备随机输入数据\n",
    "        inputs = torch.randn(batch_size, 1, 6, 6, device=device, dtype=torch.float16)\n",
    "        \n",
    "        # 预热\n",
    "        for _ in range(10):\n",
    "            with torch.no_grad():\n",
    "                _ = pytorch_model(inputs)\n",
    "                _ = triton_model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # PyTorch 模型推理\n",
    "        pytorch_times = []\n",
    "        for i in range(num_batches):\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                pytorch_output = pytorch_model(inputs)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            pytorch_times.append(end_time - start_time)\n",
    "        \n",
    "        # Triton 模型推理\n",
    "        triton_times = []\n",
    "        for i in range(num_batches):\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                triton_output = triton_model(inputs)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            triton_times.append(end_time - start_time)\n",
    "        \n",
    "        # 计算性能指标\n",
    "        avg_pytorch_time = sum(pytorch_times) / len(pytorch_times)\n",
    "        avg_triton_time = sum(triton_times) / len(triton_times)\n",
    "        speedup = avg_pytorch_time / avg_triton_time if avg_triton_time > 0 else float('inf')\n",
    "        \n",
    "        # 验证输出是否接近\n",
    "        output_diff = torch.abs(pytorch_output - triton_output).mean().item()\n",
    "        \n",
    "        # 打印结果\n",
    "        print(f\"PyTorch 平均推理时间: {avg_pytorch_time*1000:.2f} ms\")\n",
    "        print(f\"Triton  平均推理时间: {avg_triton_time*1000:.2f} ms\")\n",
    "        print(f\"加速比: {speedup:.2f}x\")\n",
    "        print(f\"输出差异 (平均绝对误差): {output_diff:.6f}\")\n",
    "        \n",
    "        # 打印一些样本输出\n",
    "        print(\"\\n样本输出比较 (前5个):\")\n",
    "        if batch_size >= 5:\n",
    "            for i in range(5):\n",
    "                print(f\"  样本 {i}: PyTorch={pytorch_output[i].item():.4f}, Triton={triton_output[i].item():.4f}\")\n",
    "        else:\n",
    "            for i in range(batch_size):\n",
    "                print(f\"  样本 {i}: PyTorch={pytorch_output[i].item():.4f}, Triton={triton_output[i].item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始推理测试...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2790889/316016411.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"model.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无法加载预训练模型，使用默认初始化权重\n",
      "复制权重: PyTorch torch.Size([8192, 36864]) -> Triton torch.Size([8192, 36864])\n",
      "复制权重: PyTorch torch.Size([4096, 8192]) -> Triton torch.Size([4096, 8192])\n",
      "复制权重: PyTorch torch.Size([2048, 4096]) -> Triton torch.Size([2048, 4096])\n",
      "复制权重: PyTorch torch.Size([1024, 2048]) -> Triton torch.Size([1024, 2048])\n",
      "复制权重: PyTorch torch.Size([256, 1024]) -> Triton torch.Size([256, 1024])\n",
      "复制权重: PyTorch torch.Size([1, 256]) -> Triton torch.Size([1, 256])\n",
      "\n",
      "==== 批次大小: 256 ====\n",
      "PyTorch 平均推理时间: 1.56 ms\n",
      "Triton  平均推理时间: 1.31 ms\n",
      "加速比: 1.19x\n",
      "输出差异 (平均绝对误差): 0.000097\n",
      "\n",
      "样本输出比较 (前5个):\n",
      "  样本 0: PyTorch=0.4995, Triton=0.4995\n",
      "  样本 1: PyTorch=0.4998, Triton=0.4995\n",
      "  样本 2: PyTorch=0.4988, Triton=0.4988\n",
      "  样本 3: PyTorch=0.4990, Triton=0.4990\n",
      "  样本 4: PyTorch=0.4988, Triton=0.4988\n",
      "\n",
      "==== 批次大小: 512 ====\n",
      "PyTorch 平均推理时间: 3.18 ms\n",
      "Triton  平均推理时间: 1.97 ms\n",
      "加速比: 1.62x\n",
      "输出差异 (平均绝对误差): 0.000090\n",
      "\n",
      "样本输出比较 (前5个):\n",
      "  样本 0: PyTorch=0.4985, Triton=0.4985\n",
      "  样本 1: PyTorch=0.4990, Triton=0.4990\n",
      "  样本 2: PyTorch=0.4995, Triton=0.4995\n",
      "  样本 3: PyTorch=0.4995, Triton=0.4995\n",
      "  样本 4: PyTorch=0.4993, Triton=0.4990\n",
      "\n",
      "==== 批次大小: 1024 ====\n",
      "PyTorch 平均推理时间: 6.17 ms\n",
      "Triton  平均推理时间: 3.84 ms\n",
      "加速比: 1.61x\n",
      "输出差异 (平均绝对误差): 0.000098\n",
      "\n",
      "样本输出比较 (前5个):\n",
      "  样本 0: PyTorch=0.4993, Triton=0.4993\n",
      "  样本 1: PyTorch=0.4985, Triton=0.4985\n",
      "  样本 2: PyTorch=0.4993, Triton=0.4993\n",
      "  样本 3: PyTorch=0.4988, Triton=0.4988\n",
      "  样本 4: PyTorch=0.4995, Triton=0.4993\n"
     ]
    }
   ],
   "source": [
    "run_inference(batch_sizes=[256, 512, 1024], num_batches=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conv2d+linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.utils.data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim     # for constructing optimizer\n",
    "from typing import Optional\n",
    "import time\n",
    "from kernels.quantize_gemm_int8 import *\n",
    "from kernels.conv2d import conv2d_triton\n",
    "\n",
    "class GDdataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.data = pd.read_csv(path)\n",
    "        SFR = torch.tensor(self.data.iloc[:, 2:46].values)\n",
    "        blocks = [SFR[:, i:i+4].reshape(-1, 2, 2) for i in range(0, 45, 5)] # 将36列中的每4列合并成一个2*2矩阵，得到9个块\n",
    "        \n",
    "        self.value = torch.cat([torch.cat(blocks[i:i+3], dim=2) for i in range(0, 9, 3)], dim=1) # 将9个块按3*3的方式拼成一个大矩阵\n",
    "        self.value = self.value.unsqueeze(1).to(torch.float32)\n",
    "        \n",
    "        self.target = torch.tensor([1.0 if x == 'OK' else 0.0 for x in self.data.iloc[:, 48].values])\n",
    "        self.target = self.target.unsqueeze(1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.value[index], self.target[index]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层\n",
    "        # input:(batch_size, 1, 6, 6), output:(batch_size, num_kernels, 3, 3)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4096, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=4096*3*3, out_features=8192),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=8192, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = x.view(x.shape[0], -1)  # (batch_size, 4096*3*3)\n",
    "        B = x.shape[0]\n",
    "        Cin = x.shape[1] * x.shape[2] * x.shape[3]  # 计算出 Cin = 4096 * 3 * 3\n",
    "        T = 1  # 设置 T = 1，因为不涉及序列长度，这里作为占位符\n",
    "        x = x.view(B, T, Cin)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], -1)    # (batch_size, 1)\n",
    "        x = self.sigmoid(x)     \n",
    "        return x\n",
    "    \n",
    "class TritonLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # 初始化权重 (out_features, in_features)\n",
    "        self.weight = nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        # 预计算量化权重\n",
    "        self.register_buffer('quantized_weight', None)\n",
    "        self.register_buffer('weight_scale', None)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.quantize_weight()  # 初始化时预量化权重\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # 标准的 PyTorch 初始化方法\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def quantize_weight(self):\n",
    "        # 转置权重以匹配 matmul 需求：从 (out_features, in_features) 到 (in_features, out_features)\n",
    "        weight_t = self.weight.t().contiguous()\n",
    "        # 按列量化（相当于原始权重的行）\n",
    "        quantized_weight, weight_scale = quantize_int8(weight_t, axis=0)\n",
    "        self.quantized_weight = quantized_weight\n",
    "        self.weight_scale = weight_scale\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # 如果处于训练模式或权重尚未量化，则量化权重\n",
    "        if self.training or self.quantized_weight is None:\n",
    "            self.quantize_weight()\n",
    "        \n",
    "        # 处理输入\n",
    "        original_shape = input.shape\n",
    "        if input.dim() > 2:\n",
    "            # 将高维输入重塑为 2D\n",
    "            input = input.reshape(-1, input.size(-1))\n",
    "        \n",
    "        # 量化输入\n",
    "        quantized_input, input_scale = quantize_int8_perrow(input)\n",
    "        \n",
    "        # 执行量化矩阵乘法\n",
    "        output = matmul_int8(quantized_input, input_scale, \n",
    "                           self.quantized_weight, self.weight_scale)\n",
    "        \n",
    "        # 添加偏置（如果存在）\n",
    "        if self.bias is not None:\n",
    "            output = output + self.bias\n",
    "        \n",
    "        # 恢复原始维度（如果需要）\n",
    "        if len(original_shape) > 2:\n",
    "            output_shape = original_shape[:-1] + (self.out_features,)\n",
    "            output = output.reshape(output_shape)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class Conv2dTriton(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True, device=None, dtype=None):\n",
    "        super(Conv2dTriton, self).__init__()\n",
    "        \n",
    "        # Handle kernel_size as int or tuple\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        \n",
    "        # Currently, the Triton implementation only supports stride = kernel_size\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        \n",
    "        assert stride == kernel_size, \"The Triton implementation only supports stride == kernel_size\"\n",
    "        assert padding == 0, \"The Triton implementation doesn't support padding\"\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        self.weight = nn.Parameter(torch.empty((out_channels, in_channels, kernel_size[0], kernel_size[1])))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        # Standard initialization as in PyTorch\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ensure input dimensions are divisible by kernel dimensions\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        assert height % self.kernel_size[0] == 0 and width % self.kernel_size[1] == 0, \\\n",
    "            f\"Input height ({height}) and width ({width}) should be divisible by kernel dimensions ({self.kernel_size})\"\n",
    "        \n",
    "        # Use the Triton implementation\n",
    "        bias_tensor = self.bias if self.bias is not None else torch.zeros(self.out_channels, device=x.device, dtype=x.dtype)\n",
    "        output = conv2d_triton(x, self.weight, bias_tensor)\n",
    "        \n",
    "        # Ensure output has the same dtype as input\n",
    "        return output.to(x.dtype)\n",
    "\n",
    "\n",
    "class NetWithTriton(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetWithTriton, self).__init__()\n",
    "        # Replace nn.Conv2d with Conv2dTriton\n",
    "        self.conv = nn.Sequential(\n",
    "            Conv2dTriton(in_channels=1, out_channels=4096, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # Use TritonLinear for fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            TritonLinear(in_features=4096*3*3, out_features=8192),\n",
    "            nn.ReLU(),\n",
    "            TritonLinear(in_features=8192, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            TritonLinear(in_features=4096, out_features=2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            TritonLinear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            TritonLinear(in_features=1024, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            TritonLinear(in_features=256, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        B = x.shape[0]\n",
    "        Cin = x.shape[1] * x.shape[2] * x.shape[3]  # Calculate Cin = 4096 * 3 * 3\n",
    "        T = 1  # Set T = 1 as placeholder\n",
    "        x = x.view(B, T, Cin)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], -1)  \n",
    "        x = self.sigmoid(x)     \n",
    "        return x\n",
    "\n",
    "\n",
    "def convert_pytorch_to_triton_model(pytorch_model):\n",
    "    \"\"\"\n",
    "    Convert standard PyTorch model to a model using TritonLinear and Conv2dTriton\n",
    "    \"\"\"\n",
    "    triton_model = NetWithTriton()\n",
    "    \n",
    "    # Copy Conv2d weights to Conv2dTriton\n",
    "    pytorch_conv = pytorch_model.conv[0]  # Get the Conv2d layer\n",
    "    triton_conv = triton_model.conv[0]    # Get the Conv2dTriton layer\n",
    "    \n",
    "    # Copy weights and bias\n",
    "    print(f\"Copying Conv weights: PyTorch {pytorch_conv.weight.shape} -> Triton {triton_conv.weight.shape}\")\n",
    "    triton_conv.weight.data.copy_(pytorch_conv.weight.data)\n",
    "    if hasattr(pytorch_conv, 'bias') and pytorch_conv.bias is not None:\n",
    "        triton_conv.bias.data.copy_(pytorch_conv.bias.data)\n",
    "    \n",
    "    # Copy other layers in the conv sequential (BatchNorm, etc.)\n",
    "    for i in range(1, len(pytorch_model.conv)):\n",
    "        print(f\"Copying layer: {type(pytorch_model.conv[i]).__name__}\")\n",
    "        triton_model.conv[i].load_state_dict(pytorch_model.conv[i].state_dict())\n",
    "    \n",
    "    # Copy linear layer weights to TritonLinear\n",
    "    pytorch_linears = [m for m in pytorch_model.fc if isinstance(m, nn.Linear)]\n",
    "    triton_linears = [m for m in triton_model.fc if isinstance(m, TritonLinear)]\n",
    "    \n",
    "    assert len(pytorch_linears) == len(triton_linears), \\\n",
    "        f\"Number of Linear layers doesn't match: PyTorch {len(pytorch_linears)} vs Triton {len(triton_linears)}\"\n",
    "    \n",
    "    for i, (pytorch_linear, triton_linear) in enumerate(zip(pytorch_linears, triton_linears)):\n",
    "        print(f\"Copying Linear {i+1} weights: PyTorch {pytorch_linear.weight.shape} -> Triton {triton_linear.weight.shape}\")\n",
    "        triton_linear.weight.data.copy_(pytorch_linear.weight.data)\n",
    "        if pytorch_linear.bias is not None:\n",
    "            triton_linear.bias.data.copy_(pytorch_linear.bias.data)\n",
    "        \n",
    "        # Update quantized weights\n",
    "        triton_linear.quantize_weight()\n",
    "    \n",
    "    return triton_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import types\n",
    "import time\n",
    "import pprint\n",
    "import contextlib\n",
    "from collections import defaultdict\n",
    "\n",
    "# 创建一个字典来存储调用次数\n",
    "call_count = {}\n",
    "# 用于跟踪被装饰的函数和装饰次数\n",
    "decorated_count = defaultdict(int)\n",
    "# 备份原始函数\n",
    "original_functions = {}\n",
    "\n",
    "def count_calls(func, module_name=None):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_count_calls(*args, **kwargs):\n",
    "        full_name = module_name + '.' + func.__name__\n",
    "        \n",
    "        # 记录开始时间\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        # 记录结束时间\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # 计算调用时间\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        if full_name not in call_count:\n",
    "            call_count[full_name] = {\"count\": 0, \"total_time\": 0.0}\n",
    "        \n",
    "        call_count[full_name][\"count\"] += 1\n",
    "        call_count[full_name][\"total_time\"] += elapsed_time\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    wrapper_count_calls._is_decorated = True\n",
    "    wrapper_count_calls._original_func = func\n",
    "    return wrapper_count_calls\n",
    "\n",
    "def decorate_function(module, attr_name):\n",
    "    \"\"\"装饰单个函数\"\"\"\n",
    "    if hasattr(module, attr_name):\n",
    "        attr = getattr(module, attr_name)\n",
    "        key = f\"{module.__name__}.{attr_name}\"\n",
    "        \n",
    "        if callable(attr):\n",
    "            # 如果函数已经被装饰，只增加引用计数\n",
    "            if hasattr(attr, '_is_decorated'):\n",
    "                decorated_count[key] += 1\n",
    "                return True\n",
    "            \n",
    "            # 否则装饰函数并保存原始函数\n",
    "            if key not in original_functions:\n",
    "                original_functions[key] = attr\n",
    "            \n",
    "            decorated_attr = count_calls(original_functions[key], module.__name__)\n",
    "            setattr(module, attr_name, decorated_attr)\n",
    "            decorated_count[key] = 1\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def restore_function(module, attr_name):\n",
    "    \"\"\"恢复单个原始函数\"\"\"\n",
    "    key = f\"{module.__name__}.{attr_name}\"\n",
    "    \n",
    "    # 减少引用计数\n",
    "    if key in decorated_count:\n",
    "        decorated_count[key] -= 1\n",
    "        \n",
    "        # 只有当引用计数为0时才恢复原始函数\n",
    "        if decorated_count[key] <= 0:\n",
    "            if key in original_functions:\n",
    "                setattr(module, attr_name, original_functions[key])\n",
    "                del decorated_count[key]\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def decorate_module(module, recursive=True, visited=None):\n",
    "    \"\"\"装饰模块中的所有函数\"\"\"\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    module_id = id(module)\n",
    "    if module_id in visited:\n",
    "        return\n",
    "    visited.add(module_id)\n",
    "    \n",
    "    for attr_name in dir(module):\n",
    "        try:\n",
    "            attr = getattr(module, attr_name)\n",
    "            \n",
    "            # 装饰函数\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                decorate_function(module, attr_name)\n",
    "            \n",
    "            # 装饰可调用对象\n",
    "            elif callable(attr) and not isinstance(attr, type):\n",
    "                decorate_function(module, attr_name)\n",
    "            \n",
    "            # 递归装饰子模块\n",
    "            elif recursive and isinstance(attr, types.ModuleType):\n",
    "                module_name = getattr(attr, '__name__', '')\n",
    "                if module_name.startswith('torch'):\n",
    "                    decorate_module(attr, recursive=True, visited=visited)\n",
    "            \n",
    "            # 装饰类\n",
    "            elif isinstance(attr, type):\n",
    "                decorate_class(attr)\n",
    "                \n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "def decorate_class(cls):\n",
    "    \"\"\"装饰类中的方法\"\"\"\n",
    "    for attr_name in dir(cls):\n",
    "        try:\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if isinstance(attr, types.FunctionType):\n",
    "                decorate_function(cls, attr_name)\n",
    "            elif attr_name in ['__add__', '__mul__', '__sub__', '__truediv__', '__matmul__', '__pow__', '__mod__']:\n",
    "                # 特殊处理运算符重载方法\n",
    "                decorate_function(cls, attr_name)\n",
    "        except (AttributeError, TypeError):\n",
    "            continue\n",
    "\n",
    "def restore_module(module, recursive=True, visited=None):\n",
    "    \"\"\"恢复模块中的所有原始函数\"\"\"\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    module_id = id(module)\n",
    "    if module_id in visited:\n",
    "        return\n",
    "    visited.add(module_id)\n",
    "    \n",
    "    for attr_name in dir(module):\n",
    "        try:\n",
    "            # 尝试恢复函数\n",
    "            restore_function(module, attr_name)\n",
    "            \n",
    "            # 递归恢复子模块\n",
    "            attr = getattr(module, attr_name)\n",
    "            if recursive and isinstance(attr, types.ModuleType):\n",
    "                module_name = getattr(attr, '__name__', '')\n",
    "                if module_name.startswith('torch'):\n",
    "                    restore_module(attr, recursive=True, visited=visited)\n",
    "            elif isinstance(attr, type):\n",
    "                restore_class(attr)\n",
    "                \n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "def restore_class(cls):\n",
    "    \"\"\"恢复类中的原始方法\"\"\"\n",
    "    for attr_name in dir(cls):\n",
    "        try:\n",
    "            restore_function(cls, attr_name)\n",
    "        except (AttributeError, TypeError):\n",
    "            continue\n",
    "\n",
    "# 重置计数器\n",
    "def reset_counters():\n",
    "    \"\"\"重置所有计数器\"\"\"\n",
    "    global call_count\n",
    "    call_count.clear()\n",
    "\n",
    "# 获取统计结果\n",
    "def get_statistics():\n",
    "    \"\"\"获取当前的统计结果\"\"\"\n",
    "    return call_count\n",
    "\n",
    "# 打印统计结果\n",
    "def print_statistics(sort_by=\"count\", top_n=None):\n",
    "    \"\"\"打印当前的统计结果\n",
    "    \n",
    "    Args:\n",
    "        sort_by: 排序依据，可以是\"count\"或\"total_time\"\n",
    "        top_n: 只显示前N个结果，默认显示所有\n",
    "    \"\"\"\n",
    "    if not call_count:\n",
    "        print(\"No statistics available.\")\n",
    "        return\n",
    "        \n",
    "    # 对结果进行排序\n",
    "    sorted_stats = sorted(call_count.items(), \n",
    "                          key=lambda x: x[1][sort_by], \n",
    "                          reverse=True)\n",
    "    \n",
    "    if top_n is not None:\n",
    "        sorted_stats = sorted_stats[:top_n]\n",
    "    \n",
    "    print(f\"{'Function Name':<50} {'Count':<10} {'Total Time (s)':<15} {'Avg Time (s)':<15}\")\n",
    "    print(\"-\" * 90)\n",
    "    for name, stats in sorted_stats:\n",
    "        avg_time = stats[\"total_time\"] / stats[\"count\"] if stats[\"count\"] > 0 else 0\n",
    "        print(f\"{name:<50} {stats['count']:<10} {stats['total_time']:<15.6f} {avg_time:<15.6f}\")\n",
    "\n",
    "# 上下文管理器，用于临时启用监控\n",
    "class Monitor:\n",
    "    def __init__(self, modules=None, reset=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            modules: 要监控的模块列表，默认为[torch]\n",
    "            reset: 是否在进入上下文前重置计数器\n",
    "        \"\"\"\n",
    "        self.modules = modules if modules is not None else [torch]\n",
    "        self.reset = reset\n",
    "    \n",
    "    def __enter__(self):\n",
    "        if self.reset:\n",
    "            reset_counters()\n",
    "        \n",
    "        # 装饰指定模块中的函数\n",
    "        for module in self.modules:\n",
    "            decorate_module(module)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # 恢复原始函数\n",
    "        for module in self.modules:\n",
    "            restore_module(module)\n",
    "\n",
    "# 创建一个更简单的上下文管理器函数\n",
    "@contextlib.contextmanager\n",
    "def monitor(modules=None, reset=False):\n",
    "    \"\"\"上下文管理器，用于在特定代码块中启用监控\n",
    "    \n",
    "    Args:\n",
    "        modules: 要监控的模块列表，默认为[torch]\n",
    "        reset: 是否在进入上下文前重置计数器\n",
    "    \"\"\"\n",
    "    with Monitor(modules=modules, reset=reset):\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(batch_sizes=[64, 128, 256, 512], num_batches=5):\n",
    "    \"\"\"\n",
    "    Run inference on Triton models and measure operator-level performance\n",
    "    \"\"\"\n",
    "    print(\"Starting inference test with real dataset...\")\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.set_device(device)  # Set default device\n",
    "    torch.cuda.empty_cache()  # Clear unused GPU memory\n",
    "    \n",
    "    # Try to load pre-trained model\n",
    "    try:\n",
    "        model_state_dict = torch.load(\"model.pt\")\n",
    "        print(\"Successfully loaded pre-trained model weights\")\n",
    "        pytorch_model = Net()\n",
    "        pytorch_model.load_state_dict(model_state_dict)\n",
    "    except:\n",
    "        print(\"Could not load pre-trained model, using default weights\")\n",
    "        pytorch_model = Net()\n",
    "    \n",
    "    # Convert model to use Triton implementations\n",
    "    pytorch_model = pytorch_model.to(device).half()\n",
    "    triton_model = convert_pytorch_to_triton_model(pytorch_model)\n",
    "    triton_model = triton_model.to(device).half()\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    triton_model.eval()\n",
    "    \n",
    "    # Create the dataset once (we'll reuse it for different batch sizes)\n",
    "    try:\n",
    "        train_dataset = GDdataset(\"./train_data.csv\")\n",
    "        print(f\"Successfully loaded dataset with {len(train_dataset)} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Test for different batch sizes\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\n==== Batch Size: {batch_size} ====\")\n",
    "        \n",
    "        # Store batches for testing - manually shuffle the dataset indices\n",
    "        indices = torch.randperm(len(train_dataset), device='cpu').tolist()\n",
    "        test_batches = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        for i in range(0, min(len(indices), batch_size * num_batches), batch_size):\n",
    "            if batch_count >= num_batches:\n",
    "                break\n",
    "                \n",
    "            # Get a batch of indices\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            if len(batch_indices) < batch_size:\n",
    "                # Skip incomplete batches\n",
    "                continue\n",
    "                \n",
    "            # Collect inputs and targets for this batch\n",
    "            batch_inputs = []\n",
    "            batch_targets = []\n",
    "            for idx in batch_indices:\n",
    "                inp, tgt = train_dataset[idx]\n",
    "                batch_inputs.append(inp)\n",
    "                batch_targets.append(tgt)\n",
    "            \n",
    "            # Stack the tensors into a batch\n",
    "            inputs = torch.stack(batch_inputs).to(device).half()\n",
    "            targets = torch.stack(batch_targets).to(device).half()\n",
    "            \n",
    "            test_batches.append((inputs, targets))\n",
    "            batch_count += 1\n",
    "        \n",
    "        # Ensure we have enough batches\n",
    "        if len(test_batches) < num_batches:\n",
    "            print(f\"Warning: Could only extract {len(test_batches)} batches instead of {num_batches}\")\n",
    "            num_actual_batches = len(test_batches)\n",
    "        else:\n",
    "            num_actual_batches = num_batches\n",
    "        \n",
    "        # Verify data shape\n",
    "        print(f\"Input shape: {test_batches[0][0].shape}\")\n",
    "        \n",
    "        # Warmup\n",
    "        for i in range(min(10, len(test_batches))):\n",
    "            inputs, _ = test_batches[i % len(test_batches)]\n",
    "            with torch.no_grad():\n",
    "                _ = triton_model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Reset counters before measurement\n",
    "        reset_counters()\n",
    "        \n",
    "        # Triton model inference with operator-level profiling\n",
    "        with monitor():\n",
    "            for i in range(num_actual_batches):\n",
    "                inputs, targets = test_batches[i]\n",
    "                with torch.no_grad():\n",
    "                    triton_output = triton_model(inputs)\n",
    "                torch.cuda.synchronize()\n",
    "        \n",
    "        # Print operator-level statistics\n",
    "        print(\"\\nOperator-level performance statistics (top 10 by total time):\")\n",
    "        print_statistics(sort_by=\"total_time\", top_n=10)\n",
    "        \n",
    "        # Print sample outputs for the last batch\n",
    "        batch_to_print = min(batch_size, triton_output.size(0))\n",
    "        print(f\"\\nSample output (first {min(5, batch_to_print)} from last batch):\")\n",
    "        for i in range(min(5, batch_to_print)):\n",
    "            print(f\"  Sample {i}: Output={triton_output[i].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference test with real dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3090321/1721778434.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"model.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load pre-trained model, using default weights\n",
      "Copying Conv weights: PyTorch torch.Size([4096, 1, 2, 2]) -> Triton torch.Size([4096, 1, 2, 2])\n",
      "Copying layer: BatchNorm2d\n",
      "Copying layer: ReLU\n",
      "Copying layer: MaxPool2d\n",
      "Copying Linear 1 weights: PyTorch torch.Size([8192, 36864]) -> Triton torch.Size([8192, 36864])\n",
      "Copying Linear 2 weights: PyTorch torch.Size([4096, 8192]) -> Triton torch.Size([4096, 8192])\n",
      "Copying Linear 3 weights: PyTorch torch.Size([2048, 4096]) -> Triton torch.Size([2048, 4096])\n",
      "Copying Linear 4 weights: PyTorch torch.Size([1024, 2048]) -> Triton torch.Size([1024, 2048])\n",
      "Copying Linear 5 weights: PyTorch torch.Size([256, 1024]) -> Triton torch.Size([256, 1024])\n",
      "Copying Linear 6 weights: PyTorch torch.Size([1, 256]) -> Triton torch.Size([1, 256])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 4 has a total capacity of 23.64 GiB of which 700.12 MiB is free. Process 2883816 has 20.67 GiB memory in use. Including non-PyTorch memory, this process has 2.27 GiB memory in use. Of the allocated memory 660.74 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(batch_sizes, num_batches)\u001b[0m\n\u001b[1;32m     23\u001b[0m pytorch_model \u001b[38;5;241m=\u001b[39m pytorch_model\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[1;32m     24\u001b[0m triton_model \u001b[38;5;241m=\u001b[39m convert_pytorch_to_triton_model(pytorch_model)\n\u001b[0;32m---> 25\u001b[0m triton_model \u001b[38;5;241m=\u001b[39m \u001b[43mtriton_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Set to evaluation mode\u001b[39;00m\n\u001b[1;32m     28\u001b[0m triton_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/triton/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.12 GiB. GPU 4 has a total capacity of 23.64 GiB of which 700.12 MiB is free. Process 2883816 has 20.67 GiB memory in use. Including non-PyTorch memory, this process has 2.27 GiB memory in use. Of the allocated memory 660.74 MiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "run_inference(batch_sizes=[256], num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(batch_sizes=[64, 128, 256, 512], num_batches=5):\n",
    "    \"\"\"\n",
    "    Run inference on both PyTorch and Triton models using the train_loader dataset\n",
    "    \"\"\"\n",
    "    print(\"Starting inference test with real dataset...\")\n",
    "    \n",
    "    # Define device\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.set_device(device)  # Set default device\n",
    "    torch.cuda.empty_cache()  # Clear unused GPU memory\n",
    "    \n",
    "    # Set the generator for sampling - fix for issue #76750\n",
    "    if device.type == 'cuda':\n",
    "        generator = torch.Generator(device=device)\n",
    "    else:\n",
    "        generator = torch.Generator()\n",
    "    \n",
    "    # Try to load pre-trained model\n",
    "    try:\n",
    "        model_state_dict = torch.load(\"model.pt\")\n",
    "        print(\"Successfully loaded pre-trained model weights\")\n",
    "        pytorch_model = Net()\n",
    "        pytorch_model.load_state_dict(model_state_dict)\n",
    "    except:\n",
    "        print(\"Could not load pre-trained model, using default weights\")\n",
    "        pytorch_model = Net()\n",
    "    \n",
    "    # Convert model to use Triton implementations\n",
    "    pytorch_model = pytorch_model.to(device).half()\n",
    "    triton_model = convert_pytorch_to_triton_model(pytorch_model)\n",
    "    triton_model = triton_model.to(device).half()\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    pytorch_model.eval()\n",
    "    triton_model.eval()\n",
    "    \n",
    "    # Create the dataset once (we'll reuse it for different batch sizes)\n",
    "    try:\n",
    "        train_dataset = GDdataset(\"./train_data.csv\")\n",
    "        print(f\"Successfully loaded dataset with {len(train_dataset)} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Test for different batch sizes\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\n==== Batch Size: {batch_size} ====\")\n",
    "        \n",
    "        # Create a new DataLoader with the current batch size\n",
    "        # Setting shuffle=False to avoid the device mismatch issue\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,  # Avoid the device mismatch with shuffle\n",
    "            num_workers=0   # Avoid multi-processing issues\n",
    "        )\n",
    "        \n",
    "        # Check if we can form at least one full batch\n",
    "        if len(train_dataset) < batch_size:\n",
    "            print(f\"Warning: Dataset size ({len(train_dataset)}) is smaller than batch size ({batch_size})\")\n",
    "        \n",
    "        # Store batches for testing - manually shuffle the dataset indices\n",
    "        indices = torch.randperm(len(train_dataset), device='cpu').tolist()  # Use CPU for indices\n",
    "        test_batches = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        for i in range(0, min(len(indices), batch_size * num_batches), batch_size):\n",
    "            if batch_count >= num_batches:\n",
    "                break\n",
    "                \n",
    "            # Get a batch of indices\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            if len(batch_indices) < batch_size:\n",
    "                # Skip incomplete batches\n",
    "                continue\n",
    "                \n",
    "            # Collect inputs and targets for this batch\n",
    "            batch_inputs = []\n",
    "            batch_targets = []\n",
    "            for idx in batch_indices:\n",
    "                inp, tgt = train_dataset[idx]\n",
    "                batch_inputs.append(inp)\n",
    "                batch_targets.append(tgt)\n",
    "            \n",
    "            # Stack the tensors into a batch\n",
    "            inputs = torch.stack(batch_inputs).to(device).half()\n",
    "            targets = torch.stack(batch_targets).to(device).half()\n",
    "            \n",
    "            test_batches.append((inputs, targets))\n",
    "            batch_count += 1\n",
    "        \n",
    "        # Ensure we have enough batches\n",
    "        if len(test_batches) < num_batches:\n",
    "            print(f\"Warning: Could only extract {len(test_batches)} batches instead of {num_batches}\")\n",
    "            num_actual_batches = len(test_batches)\n",
    "        else:\n",
    "            num_actual_batches = num_batches\n",
    "        \n",
    "        # Verify data shape\n",
    "        print(f\"Input shape: {test_batches[0][0].shape}\")\n",
    "        \n",
    "        # Warmup\n",
    "        for i in range(min(10, len(test_batches))):\n",
    "            inputs, _ = test_batches[i % len(test_batches)]\n",
    "            with torch.no_grad():\n",
    "                _ = pytorch_model(inputs)\n",
    "                _ = triton_model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # PyTorch model inference\n",
    "        pytorch_times = []\n",
    "        pytorch_outputs = []\n",
    "        for i in range(num_actual_batches):\n",
    "            inputs, targets = test_batches[i]\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                pytorch_output = pytorch_model(inputs)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            pytorch_times.append(end_time - start_time)\n",
    "            pytorch_outputs.append(pytorch_output)\n",
    "        \n",
    "        # Triton model inference\n",
    "        triton_times = []\n",
    "        triton_outputs = []\n",
    "        for i in range(num_actual_batches):\n",
    "            inputs, targets = test_batches[i]\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                triton_output = triton_model(inputs)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            triton_times.append(end_time - start_time)\n",
    "            triton_outputs.append(triton_output)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        avg_pytorch_time = sum(pytorch_times) / len(pytorch_times)\n",
    "        avg_triton_time = sum(triton_times) / len(triton_times)\n",
    "        speedup = avg_pytorch_time / avg_triton_time if avg_triton_time > 0 else float('inf')\n",
    "        \n",
    "        # Validate outputs are close\n",
    "        output_diffs = []\n",
    "        for pt_out, tr_out in zip(pytorch_outputs, triton_outputs):\n",
    "            output_diffs.append(torch.abs(pt_out - tr_out).mean().item())\n",
    "        avg_output_diff = sum(output_diffs) / len(output_diffs)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"PyTorch average inference time: {avg_pytorch_time*1000:.2f} ms\")\n",
    "        print(f\"Triton average inference time: {avg_triton_time*1000:.2f} ms\")\n",
    "        print(f\"Speedup: {speedup:.2f}x\")\n",
    "        print(f\"Output difference (mean absolute error): {avg_output_diff:.6f}\")\n",
    "        \n",
    "        # Print sample outputs for the first batch\n",
    "        batch_to_print = min(batch_size, pytorch_outputs[0].size(0))\n",
    "        print(f\"\\nSample output comparison (first {min(5, batch_to_print)} from first batch):\")\n",
    "        for i in range(min(5, batch_to_print)):\n",
    "            print(f\"  Sample {i}: PyTorch={pytorch_outputs[0][i].item():.4f}, Triton={triton_outputs[0][i].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference test with real dataset...\n",
      "Could not load pre-trained model, using default weights\n",
      "Copying Conv weights: PyTorch torch.Size([4096, 1, 2, 2]) -> Triton torch.Size([4096, 1, 2, 2])\n",
      "Copying layer: BatchNorm2d\n",
      "Copying layer: ReLU\n",
      "Copying layer: MaxPool2d\n",
      "Copying Linear 1 weights: PyTorch torch.Size([8192, 36864]) -> Triton torch.Size([8192, 36864])\n",
      "Copying Linear 2 weights: PyTorch torch.Size([4096, 8192]) -> Triton torch.Size([4096, 8192])\n",
      "Copying Linear 3 weights: PyTorch torch.Size([2048, 4096]) -> Triton torch.Size([2048, 4096])\n",
      "Copying Linear 4 weights: PyTorch torch.Size([1024, 2048]) -> Triton torch.Size([1024, 2048])\n",
      "Copying Linear 5 weights: PyTorch torch.Size([256, 1024]) -> Triton torch.Size([256, 1024])\n",
      "Copying Linear 6 weights: PyTorch torch.Size([1, 256]) -> Triton torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_548713/437780477.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"model.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded dataset with 8773 samples\n",
      "\n",
      "==== Batch Size: 256 ====\n",
      "Input shape: torch.Size([256, 1, 6, 6])\n",
      "PyTorch average inference time: 1.74 ms\n",
      "Triton average inference time: 2.72 ms\n",
      "Speedup: 0.64x\n",
      "Output difference (mean absolute error): 0.000005\n",
      "\n",
      "Sample output comparison (first 5 from first batch):\n",
      "  Sample 0: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 1: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 2: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 3: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 4: PyTorch=0.4954, Triton=0.4954\n",
      "\n",
      "==== Batch Size: 512 ====\n",
      "Input shape: torch.Size([512, 1, 6, 6])\n",
      "PyTorch average inference time: 2.88 ms\n",
      "Triton average inference time: 4.73 ms\n",
      "Speedup: 0.61x\n",
      "Output difference (mean absolute error): 0.000005\n",
      "\n",
      "Sample output comparison (first 5 from first batch):\n",
      "  Sample 0: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 1: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 2: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 3: PyTorch=0.4954, Triton=0.4956\n",
      "  Sample 4: PyTorch=0.4954, Triton=0.4954\n",
      "\n",
      "==== Batch Size: 1024 ====\n",
      "Input shape: torch.Size([1024, 1, 6, 6])\n",
      "PyTorch average inference time: 5.79 ms\n",
      "Triton average inference time: 10.57 ms\n",
      "Speedup: 0.55x\n",
      "Output difference (mean absolute error): 0.000005\n",
      "\n",
      "Sample output comparison (first 5 from first batch):\n",
      "  Sample 0: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 1: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 2: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 3: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 4: PyTorch=0.4954, Triton=0.4954\n",
      "\n",
      "==== Batch Size: 2048 ====\n",
      "Warning: Could only extract 4 batches instead of 5\n",
      "Input shape: torch.Size([2048, 1, 6, 6])\n",
      "PyTorch average inference time: 12.19 ms\n",
      "Triton average inference time: 20.56 ms\n",
      "Speedup: 0.59x\n",
      "Output difference (mean absolute error): 0.000005\n",
      "\n",
      "Sample output comparison (first 5 from first batch):\n",
      "  Sample 0: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 1: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 2: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 3: PyTorch=0.4954, Triton=0.4954\n",
      "  Sample 4: PyTorch=0.4954, Triton=0.4954\n"
     ]
    }
   ],
   "source": [
    "# torch.set_default_device('cuda:2')\n",
    "run_inference(batch_sizes=[256, 512, 1024, 2048])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_JX\n",
    "\n",
    "+ attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class JXdataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        JX = pd.read_csv(path)\n",
    "        JX_data = torch.tensor(JX.values, dtype=torch.float32)\n",
    "        self.value, self.target = JX_data[:, :-1], JX_data[:, -1]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.value[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.value)\n",
    "    \n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = JXdataset(\"./jixie_train_data.csv\")\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = JXdataset(\"./jixie_test_data.csv\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiheadAttention\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "        # regularization\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality\n",
    "        qkv = self.c_attn(x)\n",
    "        # 使用chunk更清晰地将张量分成三等份\n",
    "        q, k, v = qkv.chunk(3, dim=2)\n",
    "        \n",
    "        # 重塑为多头格式 [B, nh, T, hs]\n",
    "        head_size = self.n_embd // self.n_head\n",
    "        k = k.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
    "\n",
    "        # 计算注意力\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(head_size))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        y = att @ v\n",
    "        \n",
    "        # 重塑回原始形状\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        \n",
    "        # 输出投影\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "# 创建回归模型\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=64, n_head=4):\n",
    "        super().__init__()\n",
    "        # MHA配置\n",
    "        self.config = type('Config', (), {\n",
    "            'n_embd': hidden_dim,\n",
    "            'n_head': n_head\n",
    "        })\n",
    "        \n",
    "        # 输入嵌入\n",
    "        self.input_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # MHA层\n",
    "        self.mha = MHA(self.config)\n",
    "        \n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, input_features]\n",
    "        x = x.unsqueeze(1)  # [batch_size, 1, input_features]\n",
    "        x = self.input_embedding(x)  # [batch_size, 1, hidden_dim]\n",
    "        x = self.mha(x)  # [batch_size, 1, hidden_dim]\n",
    "        x = self.output_layer(x)  # [batch_size, 1, 1]\n",
    "        x = x.squeeze(-1).squeeze(-1)  # [batch_size]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 7/7 [00:00<00:00, 261.03it/s, loss=2.16e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 21586.188511\n",
      "测试损失: 16578.076904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 7/7 [00:00<00:00, 298.88it/s, loss=6.49e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 6493.093576\n",
      "测试损失: 2836.002197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 7/7 [00:00<00:00, 289.08it/s, loss=2.18e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 2176.597621\n",
      "测试损失: 300.843681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 7/7 [00:00<00:00, 279.54it/s, loss=935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 935.374662\n",
      "测试损失: 0.064594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 7/7 [00:00<00:00, 291.39it/s, loss=469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 468.618117\n",
      "测试损失: 90.149326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 7/7 [00:00<00:00, 287.67it/s, loss=248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 247.583329\n",
      "测试损失: 181.986626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 7/7 [00:00<00:00, 236.09it/s, loss=135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 135.105808\n",
      "测试损失: 173.409615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 7/7 [00:00<00:00, 246.25it/s, loss=76.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 76.785007\n",
      "测试损失: 79.119289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████| 7/7 [00:00<00:00, 246.83it/s, loss=34.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 34.464949\n",
      "测试损失: 10.032657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|██████████| 7/7 [00:00<00:00, 244.21it/s, loss=12.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 12.861949\n",
      "测试损失: 2.969271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|██████████| 7/7 [00:00<00:00, 247.66it/s, loss=7.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 7.158984\n",
      "测试损失: 9.560535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|██████████| 7/7 [00:00<00:00, 246.33it/s, loss=4.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 4.633578\n",
      "测试损失: 2.583803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|██████████| 7/7 [00:00<00:00, 239.08it/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.573255\n",
      "测试损失: 0.388088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|██████████| 7/7 [00:00<00:00, 246.58it/s, loss=0.938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.937782\n",
      "测试损失: 1.210484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|██████████| 7/7 [00:00<00:00, 247.96it/s, loss=0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.564787\n",
      "测试损失: 0.133461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|██████████| 7/7 [00:00<00:00, 247.52it/s, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.243963\n",
      "测试损失: 0.312365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|██████████| 7/7 [00:00<00:00, 246.82it/s, loss=0.181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.181001\n",
      "测试损失: 0.097345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|██████████| 7/7 [00:00<00:00, 247.89it/s, loss=0.106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.105916\n",
      "测试损失: 0.078510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|██████████| 7/7 [00:00<00:00, 265.70it/s, loss=0.096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.095955\n",
      "测试损失: 0.081483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 100%|██████████| 7/7 [00:00<00:00, 284.17it/s, loss=0.0841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.084088\n",
      "测试损失: 0.072042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training: 100%|██████████| 7/7 [00:00<00:00, 261.61it/s, loss=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081777\n",
      "测试损失: 0.069579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training: 100%|██████████| 7/7 [00:00<00:00, 218.56it/s, loss=0.0829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082884\n",
      "测试损失: 0.071619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training: 100%|██████████| 7/7 [00:00<00:00, 229.63it/s, loss=0.0822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082245\n",
      "测试损失: 0.070467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training: 100%|██████████| 7/7 [00:00<00:00, 229.81it/s, loss=0.0838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083759\n",
      "测试损失: 0.069627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training: 100%|██████████| 7/7 [00:00<00:00, 240.46it/s, loss=0.0847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.084670\n",
      "测试损失: 0.073262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training: 100%|██████████| 7/7 [00:00<00:00, 240.30it/s, loss=0.0844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.084396\n",
      "测试损失: 0.079057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training: 100%|██████████| 7/7 [00:00<00:00, 210.78it/s, loss=0.0869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.086885\n",
      "测试损失: 0.071393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training: 100%|██████████| 7/7 [00:00<00:00, 243.68it/s, loss=0.0839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083927\n",
      "测试损失: 0.069290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training: 100%|██████████| 7/7 [00:00<00:00, 232.32it/s, loss=0.0819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081926\n",
      "测试损失: 0.068722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training: 100%|██████████| 7/7 [00:00<00:00, 230.18it/s, loss=0.0832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083160\n",
      "测试损失: 0.071651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training: 100%|██████████| 7/7 [00:00<00:00, 233.91it/s, loss=0.0819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081919\n",
      "测试损失: 0.069127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training: 100%|██████████| 7/7 [00:00<00:00, 231.97it/s, loss=0.0813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081330\n",
      "测试损失: 0.075491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training: 100%|██████████| 7/7 [00:00<00:00, 231.77it/s, loss=0.0845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.084485\n",
      "测试损失: 0.077919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training: 100%|██████████| 7/7 [00:00<00:00, 234.30it/s, loss=0.0861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.086053\n",
      "测试损失: 0.075643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training: 100%|██████████| 7/7 [00:00<00:00, 232.85it/s, loss=0.0858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.085800\n",
      "测试损失: 0.075258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training: 100%|██████████| 7/7 [00:00<00:00, 233.06it/s, loss=0.083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082961\n",
      "测试损失: 0.079745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training: 100%|██████████| 7/7 [00:00<00:00, 235.57it/s, loss=0.0861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.086062\n",
      "测试损失: 0.068787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training: 100%|██████████| 7/7 [00:00<00:00, 237.12it/s, loss=0.0856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.085622\n",
      "测试损失: 0.068519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training: 100%|██████████| 7/7 [00:00<00:00, 234.94it/s, loss=0.0825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082515\n",
      "测试损失: 0.083489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training: 100%|██████████| 7/7 [00:00<00:00, 245.40it/s, loss=0.0909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.090859\n",
      "测试损失: 0.077634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training: 100%|██████████| 7/7 [00:00<00:00, 251.32it/s, loss=0.0864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.086436\n",
      "测试损失: 0.083288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training: 100%|██████████| 7/7 [00:00<00:00, 248.67it/s, loss=0.087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.087030\n",
      "测试损失: 0.095852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training: 100%|██████████| 7/7 [00:00<00:00, 245.56it/s, loss=0.0857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.085709\n",
      "测试损失: 0.077419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training: 100%|██████████| 7/7 [00:00<00:00, 251.46it/s, loss=0.0832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083217\n",
      "测试损失: 0.069281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training: 100%|██████████| 7/7 [00:00<00:00, 249.23it/s, loss=0.081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.080957\n",
      "测试损失: 0.068648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training: 100%|██████████| 7/7 [00:00<00:00, 233.14it/s, loss=0.0844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.084388\n",
      "测试损失: 0.068975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training: 100%|██████████| 7/7 [00:00<00:00, 236.02it/s, loss=0.081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081033\n",
      "测试损失: 0.074838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training: 100%|██████████| 7/7 [00:00<00:00, 238.66it/s, loss=0.0892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.089183\n",
      "测试损失: 0.080680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training: 100%|██████████| 7/7 [00:00<00:00, 216.89it/s, loss=0.0869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.086909\n",
      "测试损失: 0.069070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training: 100%|██████████| 7/7 [00:00<00:00, 214.83it/s, loss=0.0829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082919\n",
      "测试损失: 0.069141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 Training: 100%|██████████| 7/7 [00:00<00:00, 236.54it/s, loss=0.0826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082578\n",
      "测试损失: 0.071304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 Training: 100%|██████████| 7/7 [00:00<00:00, 236.60it/s, loss=0.0839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083881\n",
      "测试损失: 0.068956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 Training: 100%|██████████| 7/7 [00:00<00:00, 226.52it/s, loss=0.0858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.085808\n",
      "测试损失: 0.068190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 Training: 100%|██████████| 7/7 [00:00<00:00, 238.29it/s, loss=0.0836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083562\n",
      "测试损失: 0.068037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Training: 100%|██████████| 7/7 [00:00<00:00, 222.96it/s, loss=0.0823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082265\n",
      "测试损失: 0.070074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 Training: 100%|██████████| 7/7 [00:00<00:00, 229.11it/s, loss=0.0853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.085257\n",
      "测试损失: 0.076599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 Training: 100%|██████████| 7/7 [00:00<00:00, 239.17it/s, loss=0.0839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083850\n",
      "测试损失: 0.074015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 Training: 100%|██████████| 7/7 [00:00<00:00, 269.74it/s, loss=0.0827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082654\n",
      "测试损失: 0.082335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59 Training: 100%|██████████| 7/7 [00:00<00:00, 269.12it/s, loss=0.0875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.087489\n",
      "测试损失: 0.134921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60 Training: 100%|██████████| 7/7 [00:00<00:00, 268.93it/s, loss=0.096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.096013\n",
      "测试损失: 0.091820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61 Training: 100%|██████████| 7/7 [00:00<00:00, 270.08it/s, loss=0.0871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.087086\n",
      "测试损失: 0.070920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62 Training: 100%|██████████| 7/7 [00:00<00:00, 269.51it/s, loss=0.0814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081364\n",
      "测试损失: 0.067781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63 Training: 100%|██████████| 7/7 [00:00<00:00, 272.67it/s, loss=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081826\n",
      "测试损失: 0.068446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64 Training: 100%|██████████| 7/7 [00:00<00:00, 270.04it/s, loss=0.0866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.086586\n",
      "测试损失: 0.068074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65 Training: 100%|██████████| 7/7 [00:00<00:00, 257.26it/s, loss=0.0899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.089906\n",
      "测试损失: 0.086352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66 Training: 100%|██████████| 7/7 [00:00<00:00, 270.92it/s, loss=0.0917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.091701\n",
      "测试损失: 0.095199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67 Training: 100%|██████████| 7/7 [00:00<00:00, 269.35it/s, loss=0.0924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.092393\n",
      "测试损失: 0.072737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68 Training: 100%|██████████| 7/7 [00:00<00:00, 234.42it/s, loss=0.0835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083486\n",
      "测试损失: 0.073228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69 Training: 100%|██████████| 7/7 [00:00<00:00, 233.26it/s, loss=0.0882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.088164\n",
      "测试损失: 0.067913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70 Training: 100%|██████████| 7/7 [00:00<00:00, 236.65it/s, loss=0.0823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082281\n",
      "测试损失: 0.068187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71 Training: 100%|██████████| 7/7 [00:00<00:00, 236.90it/s, loss=0.0836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083640\n",
      "测试损失: 0.068828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72 Training: 100%|██████████| 7/7 [00:00<00:00, 234.06it/s, loss=0.0843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.084342\n",
      "测试损失: 0.068088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73 Training: 100%|██████████| 7/7 [00:00<00:00, 223.68it/s, loss=0.0813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081275\n",
      "测试损失: 0.067476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74 Training: 100%|██████████| 7/7 [00:00<00:00, 226.55it/s, loss=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081814\n",
      "测试损失: 0.068171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75 Training: 100%|██████████| 7/7 [00:00<00:00, 236.40it/s, loss=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081772\n",
      "测试损失: 0.071496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76 Training: 100%|██████████| 7/7 [00:00<00:00, 238.84it/s, loss=0.0842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.084245\n",
      "测试损失: 0.067408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77 Training: 100%|██████████| 7/7 [00:00<00:00, 234.20it/s, loss=0.0833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083328\n",
      "测试损失: 0.067239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78 Training: 100%|██████████| 7/7 [00:00<00:00, 239.15it/s, loss=0.0801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.080055\n",
      "测试损失: 0.067599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79 Training: 100%|██████████| 7/7 [00:00<00:00, 233.64it/s, loss=0.0809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.080892\n",
      "测试损失: 0.067788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80 Training: 100%|██████████| 7/7 [00:00<00:00, 235.69it/s, loss=0.0974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.097443\n",
      "测试损失: 0.069945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81 Training: 100%|██████████| 7/7 [00:00<00:00, 236.88it/s, loss=0.0968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.096778\n",
      "测试损失: 0.140221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82 Training: 100%|██████████| 7/7 [00:00<00:00, 236.24it/s, loss=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.107631\n",
      "测试损失: 0.071547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83 Training: 100%|██████████| 7/7 [00:00<00:00, 238.41it/s, loss=0.0847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.084735\n",
      "测试损失: 0.069903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84 Training: 100%|██████████| 7/7 [00:00<00:00, 234.34it/s, loss=0.0834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.083385\n",
      "测试损失: 0.066957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85 Training: 100%|██████████| 7/7 [00:00<00:00, 234.97it/s, loss=0.0817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081705\n",
      "测试损失: 0.067039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86 Training: 100%|██████████| 7/7 [00:00<00:00, 235.27it/s, loss=0.0811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081121\n",
      "测试损失: 0.067284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87 Training: 100%|██████████| 7/7 [00:00<00:00, 253.43it/s, loss=0.0815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081533\n",
      "测试损失: 0.070372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88 Training: 100%|██████████| 7/7 [00:00<00:00, 248.89it/s, loss=0.0802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.080235\n",
      "测试损失: 0.069789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89 Training: 100%|██████████| 7/7 [00:00<00:00, 236.29it/s, loss=0.0817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.081666\n",
      "测试损失: 0.068913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90 Training: 100%|██████████| 7/7 [00:00<00:00, 230.01it/s, loss=0.0824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082417\n",
      "测试损失: 0.067113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91 Training: 100%|██████████| 7/7 [00:00<00:00, 238.17it/s, loss=0.0822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.082175\n",
      "测试损失: 0.100871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92 Training: 100%|██████████| 7/7 [00:00<00:00, 232.87it/s, loss=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.107946\n",
      "测试损失: 0.074035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93 Training: 100%|██████████| 7/7 [00:00<00:00, 244.32it/s, loss=0.0894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.089435\n",
      "测试损失: 0.067398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94 Training: 100%|██████████| 7/7 [00:00<00:00, 235.34it/s, loss=0.0864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.086382\n",
      "测试损失: 0.103728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95 Training: 100%|██████████| 7/7 [00:00<00:00, 251.06it/s, loss=0.0977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.097692\n",
      "测试损失: 0.070654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96 Training: 100%|██████████| 7/7 [00:00<00:00, 251.40it/s, loss=0.0994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.099357\n",
      "测试损失: 0.073802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97 Training: 100%|██████████| 7/7 [00:00<00:00, 253.84it/s, loss=0.0998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.099817\n",
      "测试损失: 0.086090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98 Training: 100%|██████████| 7/7 [00:00<00:00, 246.24it/s, loss=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.105183\n",
      "测试损失: 0.125703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 Training: 100%|██████████| 7/7 [00:00<00:00, 251.02it/s, loss=0.0977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.097684\n",
      "测试损失: 0.075260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 Training: 100%|██████████| 7/7 [00:00<00:00, 253.61it/s, loss=0.0881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.088096\n",
      "测试损失: 0.068274\n",
      "训练完成!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练函数\n",
    "def train_loop(model, train_loader, optimizer, loss_fn, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        # 将数据移至设备\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        output = model(data)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = loss_fn(output, target)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        \n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 更新总损失\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 更新进度条\n",
    "        pbar.set_postfix({\"loss\": total_loss / (batch_idx + 1)})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"训练损失: {avg_loss:.6f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# 测试函数\n",
    "def test_loop(model, test_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # 将数据移至设备\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            output = model(data)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = loss_fn(output, target)\n",
    "            \n",
    "            # 更新总损失\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    print(f\"测试损失: {avg_loss:.6f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 超参数\n",
    "    input_dim = 4  # 输入特征数\n",
    "    hidden_dim = 64\n",
    "    n_head = 4\n",
    "    learning_rate = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    num_epochs = 100\n",
    "    \n",
    "    # 创建模型\n",
    "    model = RegressionModel(input_dim, hidden_dim, n_head).to(device)\n",
    "    \n",
    "    # 定义优化器\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # 训练历史\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_loop(model, train_loader, optimizer, loss_func, device, epoch)\n",
    "        test_loss = test_loop(model, test_loader, loss_func, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # 这里可以添加早停逻辑\n",
    "    \n",
    "    # 绘制训练和测试损失曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='training loss')\n",
    "    plt.plot(test_losses, label='test loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss (MSE)')\n",
    "    plt.title('test vs train loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('loss_plot.png')\n",
    "    \n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), 'regression_model.pth')\n",
    "    \n",
    "    print(\"训练完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
